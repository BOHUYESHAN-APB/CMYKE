# CMYKE Architecture (Draft)

This document captures the base architecture so the UI can scale toward a
realtime, multimodal agent runtime without breaking core UX.

## Goals

- ChatGPT-style UX first: multi-session chat, message queue, exportable logs.
- Four-tier memory model that can grow into SQLite + vector DB backends.
- Clear separation between UI, domain models, and storage to support future
  Rust core + optional Python extensions.
- Dual-mode runtime: standard LLM for tool-heavy workflows and realtime
  voice models for low-latency conversation.
- Reserve avatar rendering slots (Live2D/Live3D) with shared expression events.

## Modules

- UI (Flutter)
  - Chat shell, session sidebar, message list, composer, memory panel.
  - Avatar stage container for Live2D/Live3D render surfaces.
  - Works without any backend; ready to bind to realtime gateway later.
- Domain Models
  - `ChatSession`, `ChatMessage`, `MemoryRecord`, `MemoryTier`.
- Repositories
  - `ChatRepository`: owns sessions, active session, message queue.
  - `MemoryRepository`: owns memory tiers and retrieval counts.
  - `SettingsRepository`: stores model routing + provider catalogs.
- Services
  - `LocalDatabase`: SQLite persistence in `Documents/cmyke/`.
  - `LocalStorage`: legacy JSON migration support.
  - `ChatExportService`: exports logs to `Documents/cmyke/exports/`.
  - `LlmClient`: chat + embedding calls (OpenAI-compatible + Ollama).

## Agent Roles (Draft)

- Standard LLM
  - Primary agent for tool-heavy workflows and document generation.
  - Can directly trigger tool calls when in Standard mode.
- Universal Agent (Standard-only)
  - Planner + executor pipeline for deep research and multi-step workflows.
  - Always uses base persona + standard LLM provider (no realtime dependency).
- Realtime Voice Model
  - Low-latency speech dialog; avoids heavy tool calls.
  - Emits lightweight emotion hints (optional) for avatar expression.
- Control/Planner Agent
  - Reads context + memory, decides tool calls on behalf of realtime model.
  - Outputs expression events for avatar synchronization.
- Deep Search Agent (planned)
  - Multi-source retrieval, citation tracking, structured summaries.
- Deep Research Agent (planned)
  - Task decomposition, evidence chain, report output (docs/tables).

## Runtime Routing (Draft)

Standard mode:
- User -> Standard LLM -> Tool Router -> Tool Executor -> Memory/Context.

Realtime mode:
- User -> Realtime Voice Model (dialog)
- Control/Planner Agent -> Tool Router -> Tool Executor -> Memory/Context
- Expression Orchestrator -> Avatar Stage (Live2D/Live3D)

## Memory Tiers

1) Context (in-session)
   - Short-term context window for the active chat.
   - Persisted with `session_id`; deleting a session clears its context records.
2) Cross-session memory
   - Frequently used persona facts that can be injected into system prompts.
3) Autonomous memory
   - Self-saved insights from the model (text/image summaries).
4) External knowledge base
   - User-imported professional data; only fetched on-demand.

Memory records carry a lightweight `scope` tag to prevent domain mixing:
`brain.user` for persona/context memory, `knowledge.docs` for external knowledge.

Current storage uses SQLite for local persistence with optional vector
backends (SQLite + FTS5, LanceDB, Qdrant, etc.) without UI changes.

## Model Routing (Draft)

- Standard LLM stack: LLM + Vision Agent + TTS + STT.
- Realtime stack: single realtime voice model (audio in/out, barge-in).
- Omni stack: single full-modal model (text/vision/audio).

These are configured in-app, backed by a provider catalog for each kind
(LLM, Vision Agent, Realtime, Omni, TTS, STT).

Standard LLM mode can call tools directly. Realtime mode uses a control
agent to handle tool calls and advanced workflows.

## Current Integration Notes

- Standard + Realtime routes use OpenAI-compatible `/v1/chat/completions`
  (streaming enabled).
- Embedding retrieval uses `/v1/embeddings` when configured; otherwise
  vector retrieval is disabled.
- Voice input/output is currently handled locally via STT/TTS to support
  barge-in testing. Native realtime audio WS integration is planned next.
- Provider protocols supported: OpenAI-compatible (OpenAI/SiliconFlow/DashScope/
  LM Studio) and Ollama native (`/api/chat`).

## Live3D / VRM (VRoid) Notes

- Target format: VRM 1.0 (VRoid Studio å¯¼å‡º). Rendering SDK plan: three-vrm (Web) / UniVRM (Unity).
- Mapping: `<|EMOTE_*|>` â†’ Emotion/Action Agent â†’ ExpressionEvent â†’ VRM BlendShapeClip (configurableè¡¨æƒ…æ˜ å°„); LipSyncFrame (AA/EE/IH/OH/OU) â†’ Mouth blendshapes; StageAction â†’ Humanoid åŠ¨ä½œ/Animator triggerã€‚
- Separation of concerns: Realtime/Omni æ¨¡å‹ä»…è¾“å‡ºå¯¹è¯ + è½»é‡è¡¨æƒ…æç¤ºï¼›Control/Planner è§¦å‘å·¥å…·è°ƒç”¨ï¼›Emotion/Action Agent è´Ÿè´£è¡¨æƒ…/åŠ¨ä½œï¼›å˜´å‹ç”±éŸ³é¢‘é©±åŠ¨ã€‚
- Licensing: ä¸å†…ç½®ç¬¬ä¸‰æ–¹æ¨¡å‹ï¼›ç”¨æˆ·åŠ è½½è‡ªæœ‰/æˆæƒ VRMï¼Œä¿ç•™åŸè®¸å¯ï¼›SDK ä¾èµ–ï¼ˆthree-vrm/UniVRMï¼‰éµå¾ª MITã€‚

### Live3D æ·±åŒ–è¿ç§»ï¼ˆStudying/airi-mainï¼‰

- å§¿æ€é©±åŠ¨ï¼šç§»æ¤ `pose-to-vrm` / `apply-pose-to-vrm` æ€è·¯ï¼ˆæ–¹å‘+poleã€rest dir/poleã€ç¿»è½¬æŠ‘åˆ¶ã€å¹³æ»‘ slerpï¼‰ï¼ŒJS ä¾§ `applyPose` æ”¯æŒï¼š
  - bones å››å…ƒæ•°ç›´é©±ã€‚
  - targetsï¼ˆdir+poleï¼‰é©±åŠ¨ã€‚
  - worldLandmarksï¼ˆmediapipe-likeï¼‰è‡ªåŠ¨ç”Ÿæˆ targetsã€‚
- é—²ç½®åŠ¨ä½œï¼šç§»æ¤ `useBlink`ã€`useIdleEyeSaccades`ã€`useVRMEmote` é€»è¾‘ï¼Œè®©æ¨¡å‹åœ¨åŸºç¡€æ¨¡å¼ä¸‹è‡ªç„¶çœ¨çœ¼ã€æ³¨è§†æ¼‚ç§»ã€è¡¨æƒ…è¿‡æ¸¡ä¸å‘¼å¸å¾®åŠ¨ã€‚
- åŠ¨ç”»ï¼šå¼•å…¥ `@pixiv/three-vrm-animation`ï¼ŒåŠ è½½ `idle_loop.vrma` ä½œä¸ºåŸºç¡€ idle åŠ¨ç”»ï¼Œå¹¶é€šè¿‡ AnimationMixer æ’­æ”¾ã€‚
- LookAtï¼šä½¿ç”¨ `VRMLookAtQuaternionProxy` ä½œä¸º lookAt åŠ¨ç”»æ”¯æ’‘ã€‚

## MCP and Skills (Draft)

- MCP Client
  - Tool registry, server discovery, health checks, permissions, retries.
  - Unified tool invocation path for both Standard and Realtime modes.
- Skill Registry
  - Declarative workflows that bind to MCP tools and policy rules.
  - Supports input schema, tool steps, memory writes, and output templates.
- Execution Policy
  - Standard LLM can call tools directly via Tool Router.
  - Realtime mode routes tool calls through Control/Planner Agent.
  - Deep Search/Research agents can run background tool plans.
- Result Handling
  - Tool outputs persist to Memory/Context with citations.
  - Expression events can be emitted alongside tool results.

```mermaid
sequenceDiagram
  participant User
  participant UI
  participant ModeRouter
  participant LLM
  participant Control
  participant ToolRouter
  participant MCP
  participant Tool
  participant Memory

  User->>UI: prompt/voice
  UI->>ModeRouter: request
  alt Standard mode
    ModeRouter->>LLM: prompt
    LLM->>ToolRouter: tool call
  else Realtime mode
    ModeRouter->>Control: context
    Control->>ToolRouter: tool call
  end
  ToolRouter->>MCP: invoke tool
  MCP->>Tool: execute
  Tool-->>MCP: result
  MCP-->>ToolRouter: result
  ToolRouter-->>Memory: persist + embeddings
  ToolRouter-->>UI: result render
```

## Logical Architecture (Draft)

```mermaid
flowchart LR
  subgraph UI[Flutter UI]
    Chat[Chat UI]
    Voice[Voice UI]
    Avatar[Avatar Stage\nLive2D/Live3D]
    Settings[Config UI]
  end

  subgraph Core[Runtime Core]
    ModeRouter[Mode Router]
    ContextBuilder[Context Builder]
    ToolRouter[Tool Router]
    ToolExec[Tool Executor]
    Expression[Expression Orchestrator]
  end

  subgraph Agents[Agents]
    LLM[Standard LLM]
    RT[Realtime Voice Model]
    Control[Control/Planner Agent]
    DeepSearch[Deep Search Agent]
    DeepResearch[Deep Research Agent]
  end

  subgraph Storage[Memory and Store]
    SQL[(SQLite)]
    Vector[(Vector Index)]
    Media[(Media Store)]
  end

  subgraph Tools[Tools]
    Web[Web Search]
    Doc[Doc Builder]
    Img[Image Gen/Analyze]
    Sys[Local Tools]
  end

  Chat --> ModeRouter
  Voice --> ModeRouter

  ModeRouter -- Standard --> LLM
  LLM --> ToolRouter

  ModeRouter -- Realtime --> RT
  RT --> Expression --> Avatar
  ContextBuilder --> Control
  Control --> ToolRouter

  ToolRouter --> ToolExec --> Tools
  ToolExec --> ContextBuilder
  ContextBuilder --> SQL
  ContextBuilder --> Vector
  ContextBuilder --> Media

  DeepSearch --> ToolRouter
  DeepResearch --> ToolRouter
  DeepSearch --> ContextBuilder
  DeepResearch --> ContextBuilder
```

## Layered Hierarchy (Standard vs Realtime)

- UI Layer: Chat/Voice/Avatar entrypoints; emits prompt/audio and receives text/audio/expression events.
- Mode Router: Splits Standard vs Realtime paths.
- Standard Path (å·¥å…·å‹å¥½): Base LLM å¯ç›´æ¥ Tool Router -> MCP/Skills -> å·¥å…·ï¼›ç»“æœå†™å…¥ Memory/Vectorã€‚
- Realtime Path (ä½å»¶è¿Ÿ): Realtime Voice/Omni æ¨¡å‹ä¸“æ³¨å¯¹è¯+è¯­éŸ³ï¼›ä¸ç›´æ¥å·¥å…·è°ƒç”¨ã€‚Control/Planner Agent è¯»å–ä¸Šä¸‹æ–‡ä¸ä¸»æ¨¡å‹çŠ¶æ€ï¼Œè§¦å‘å·¥å…·/æœç´¢ï¼›Emotion/Action Agent ç”Ÿæˆè¡¨æƒ…/åŠ¨ä½œäº‹ä»¶é©±åŠ¨ Live3Dã€‚
- Deep Search/Research Agents: é‡ä»»åŠ¡ç®¡çº¿ï¼Œå¯è¢« Standard è°ƒç”¨ï¼Œä¹Ÿå¯è¢« Realtime æ§åˆ¶ä»£ç†å¼‚æ­¥å”¤èµ·ï¼Œå†æŠŠæ‘˜è¦å›æµã€‚
- Memory/Store: SQLite + Vectorï¼›ç»Ÿä¸€ä¸ºä¸¤æ¡è·¯å¾„æä¾›ä¸Šä¸‹æ–‡ã€‚

```mermaid
flowchart TD
  UI[Chat/Voice/Avatar UI] --> Router
  Router -- Standard --> StdLLM[Base LLM]
  StdLLM --> ToolRouter[Tool Router/MCP/Skills]
  ToolRouter --> Tools[Web/Search/Code/Doc/etc.]
  Tools --> Memory[(SQLite + Vector)]
  StdLLM --> Memory

  Router -- Realtime --> RT[Realtime Voice/Omni]
  RT --> ExprAgent[Emotion/Action Agent]
  ExprAgent --> Avatar[Live3D Stage]
  RT --> CtrlAgent[Control/Planner Agent]
  CtrlAgent --> ToolRouter
  CtrlAgent --> ExprAgent

  DeepSearch[Deep Search Agent] --> ToolRouter
  DeepResearch[Deep Research Agent] --> ToolRouter
  ToolRouter --> Memory
  Memory --> CtrlAgent
```

Notes:
- Realtime/FunAudioLLM ä¸åšå·¥å…·è°ƒç”¨ï¼Œæ‰€æœ‰å·¥å…·/æœç´¢ç”± Control/Planner Agent ä»£ç†ã€‚
- Omni æ¨¡å‹å¯é€‰ç›´è¿å·¥å…·ï¼Œä½†ä»å»ºè®®ç» ToolRouter ç»Ÿä¸€é‰´æƒ/è·¯ç”±ã€‚
- è¡¨æƒ…/åŠ¨ä½œäº‹ä»¶ä¸å˜´å‹é©±åŠ¨è§£è€¦ï¼šEmotion/Action Agent è¾“å‡ºè¡¨æƒ…ï¼ŒéŸ³é¢‘æµé©±åŠ¨å˜´å‹ã€‚

## Control/Tool/Expression Flows (Detailed)

```mermaid
flowchart LR
  subgraph Realtime
    RT[Realtime/Omni Model]
    Ctrl[Control/Planner Agent]
    Expr[Emotion/Action Agent]
  end
  subgraph Standard
    LLM[Base LLM]
  end
  subgraph Tools
    Router[ToolRouter/MCP/Skills]
    T[Tools/Search/Code/Doc]
  end
  Memory[(SQLite + Vector)]
  Avatar[Live3D Stage]

  RT --> Ctrl
  RT --> Expr
  Expr --> Avatar
  Ctrl --> Router
  LLM --> Router
  Router --> T --> Router
  Router --> Memory
  Memory --> Ctrl
  Memory --> LLM
```

- Realtime æ¨¡å‹ä¸“æ³¨å¯¹è¯/è¯­éŸ³ï¼›ä¸ç›´æ¥è°ƒç”¨å·¥å…·ã€‚
- Control/Planner è§£ææ„å›¾ä¸æŒ‡ä»¤ï¼Œå‘èµ· ToolRouter è°ƒç”¨ï¼Œç”Ÿæˆè¡¨æƒ…/åŠ¨ä½œäº‹ä»¶ã€‚
- Emotion/Action Agent é©±åŠ¨ Live3Dï¼›å˜´å‹ç”±éŸ³é¢‘æµç‹¬ç«‹é©±åŠ¨ã€‚
- Standard LLM ç›´æ¥é€šè¿‡ ToolRouter ä½¿ç”¨ MCP/Skills/å·¥å…·ï¼›ç»“æœå†™å…¥ Memory/Vectorã€‚
## Runtime Evolution (Planned)

- Rust Core
  - Realtime event bus (audio/text/tool events).
  - Session occupancy state machine (idle -> listening -> processing -> speaking).
- Optional Python Extensions
  - Self-hosted TTS/STT/LLM services via HTTPS.
  - MCP-compatible tool servers and adapters.

## Next Milestones

- Wire the chat UI to a realtime gateway (WS/SSE).
- Stabilize SQLite schema + vector retrieval backfill.
- Add file uploads and voice capture flows.
- Add avatar stage with Live2D/Live3D switching + expression events.
- Implement deep search + deep research workflows.

## Live3D é«˜é˜¶æ§åˆ¶æ¨¡å¼ï¼ˆè§„åˆ’ï¼‰

ç›®æ ‡ï¼šåœ¨åŸºç¡€æ¨¡å¼ï¼ˆæœ¬åœ° WebView æ¸²æŸ“ + æŒ‰é’®åŠ¨ä½œ/è¡¨æƒ…ï¼‰ä¹‹å¤–ï¼Œå¢åŠ é«˜é˜¶æ¨¡å¼ï¼Œæ”¯æŒå¤–éƒ¨åŠ¨æ•/äººå½¢æœºå™¨äºº/ç¬¬ä¸‰æ–¹å¼•æ“é©±åŠ¨ VRMï¼Œå¹¶èƒ½å‘å…¶ä»–è½¯ä»¶ï¼ˆå¦‚ VRChatï¼‰è¾“å‡ºæ§åˆ¶ã€‚

### æ§åˆ¶æ¨¡å¼
- åŸºç¡€æ¨¡å¼ï¼ˆå½“å‰é»˜è®¤ï¼‰ï¼š
  - è½»é‡åŠ¨ä½œ/è¡¨æƒ…/é—²ç½®å¾®åŠ¨ï¼›æŒ‰é’®è§¦å‘æŒ¥æ‰‹/ç‚¹å¤´/è¡¨æƒ…ã€‚
  - åœ¨ WebView å†…çš„ JS ä½¿ç”¨æœ¬åœ°é€»è¾‘ï¼ˆapplyMotion/applyExpressionï¼‰ã€‚
- é«˜é˜¶æ¨¡å¼ï¼ˆè§„åˆ’ï¼‰ï¼š
  - WebView æš´éœ² pplyPose(pose) JS æ¥å£ï¼Œæ¥æ”¶å¤–éƒ¨éª¨æ¶/è¡¨æƒ…/å£å‹é©±åŠ¨ã€‚
  - Flutter ä¾§ Live3D å¡ç‰‡æä¾›æ¨¡å¼åˆ‡æ¢ï¼šbasic/advancedï¼Œå¹¶å°†æ¨¡å¼ä¸‹å‘ç»™ WebViewã€‚

### VRM å¯æ§é€šé“ï¼ˆéœ€æšä¸¾å¹¶è¯Šæ–­ï¼‰
- éª¨éª¼ï¼ˆHumanoidï¼‰ï¼šå¤´/é¢ˆ/è„Š/èƒ¸/é«‹/è‚©/è‚˜/è…•/æ‰‹/è…¿/è†/è¸ï¼›ç¼ºéª¨éœ€ fallbackã€‚
- è¡¨æƒ…ï¼ˆExpressionManagerï¼‰ï¼šVRM 1.0 é¢„è®¾å°å†™ï¼›è‡ªå®šä¹‰è¡¨æƒ…éœ€æšä¸¾ã€‚
- å£å‹ï¼ˆVisemeï¼‰ï¼šaa/ih/uu/ee/ohã€‚
- åŠ¨ä½œç‰‡æ®µï¼ˆå¯é€‰ï¼‰ï¼šVRMA/BVH/MMD è½¬æ¢ç‰‡æ®µä½œä¸ºå…œåº•ã€‚

### Pose â†’ VRM æ˜ å°„æ¡†æ¶ï¼ˆå‚è€ƒ Studying/airi-mainï¼‰
- å‚è€ƒï¼šStudying/airi-main/packages/model-driver-mediapipe/src/three/pose-to-vrm.tsã€pply-pose-to-vrm.tsã€‚
- æµç¨‹ï¼š
  1) è½½å…¥ VRM åæ‰“å°éª¨éª¼/è¡¨æƒ…/viseme åˆ—è¡¨ï¼ˆè¯Šæ–­æ—¥å¿—ï¼‰ã€‚
  2) åæ ‡ç³»å¯¹é½ï¼šç»Ÿä¸€å³æ‰‹åæ ‡ï¼Œè®°å½•ä¼‘æ­¢å§¿æ€ quaternion ä½œä¸ºåç§»åŸºå‡†ã€‚
  3) æ¯å¸§ pplyPose(pose)ï¼šå¯¹éª¨éª¼ one.quaternion.slerp(target, alpha) å¹³æ»‘ï¼›ç¼ºéª¨ fallbackï¼›å¯¹è‚˜/è†é™å¹…é˜²ç©¿æ¨¡ã€‚
  4) è¡¨æƒ…/å£å‹ï¼šç”¨ pose æ¦‚ç‡é©±åŠ¨ xpressionManager å’Œ visemeï¼ˆVRM 1.0 å°å†™é¢„è®¾ï¼‰ã€‚
  5) åŠ¨ä½œç‰‡æ®µä½œä¸ºå…œåº•ï¼ˆwave/nod/point ç­‰ï¼‰ï¼Œå½“å¤–éƒ¨é©±åŠ¨ç¼ºå¤±æ—¶è§¦å‘ã€‚

### è¾“å…¥é€‚é…ä¸è¾“å‡ºæ‰©å±•
- è¾“å…¥ï¼šFlutter ä¾§é€šè¿‡ Live3DBridge å°†å¤–éƒ¨ç®—æ³•çš„ pose JSON é€ä¼ åˆ° WebView pplyPoseï¼›ç»Ÿä¸€æ ¼å¼ï¼ˆå…³èŠ‚å››å…ƒæ•°ï¼Œå³æ‰‹åæ ‡ï¼Œå«è¡¨æƒ…/å£å‹æ¦‚ç‡ï¼‰ã€‚
- è¾“å‡ºï¼šé¢„ç•™æ¥å£å°†æœ¬åœ°å§¿æ€/è¡¨æƒ…æµè¾“å‡ºåˆ°å…¶ä»–è½¯ä»¶ï¼ˆå¦‚ VRChatï¼‰ï¼Œä½œä¸ºæœªæ¥é›†æˆï¼š
  - VRChat OSC/Avatar æ§åˆ¶ï¼šå°† pose/è¡¨æƒ…æ˜ å°„åˆ° VRChat Avatar å‚æ•°ï¼ˆéœ€ç‹¬ç«‹æ¨¡å—ï¼‰ã€‚
  - è§†è§‰æ¥å…¥ï¼šåœ¨é«˜é˜¶æ¨¡å¼ä¸‹å¯é€‰æ¥å…¥è§†è§‰æµï¼Œé©±åŠ¨è§†çº¿/å¤´éƒ¨æœå‘ã€‚

### åç»­å®æ–½é¡ºåº
1) WebViewï¼šåŠ å…¥æ§åˆ¶æ¨¡å¼å¼€å…³ã€éª¨éª¼/è¡¨æƒ…è¯Šæ–­ã€pplyPose(pose) æ¡†æ¶ï¼ˆå«å¹³æ»‘/é™å¹…å ä½ï¼‰ã€‚
2) Flutterï¼šLive3D å¡ç‰‡å¢åŠ  basic/advanced åˆ‡æ¢ï¼Œä¸‹å‘æ¨¡å¼ï¼›Live3DBridge å¢åŠ  sendPose é€ä¼ ã€‚
3) æ˜ å°„è¡¨ï¼šæ ¹æ®è¯Šæ–­ç»“æœè°ƒæ•´ rm_mapping.dartï¼ˆè¡¨æƒ…/å£å‹ï¼‰ï¼Œå¹¶ä¸ºç¼ºéª¨åš fallbackã€‚
4) è¾“å‡ºæ‰©å±•ï¼ˆåç»­ï¼‰ï¼šVRChat/å…¶ä»–è½¯ä»¶çš„æ¡¥æ¥æ¨¡å—ï¼Œå°† pose/è¡¨æƒ…è½¬æ¢ä¸ºç›®æ ‡åè®®ï¼ˆå¦‚ OSCï¼‰ã€‚

