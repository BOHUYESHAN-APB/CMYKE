openapi: 3.0.0
info:
  title: SiliconFlow API
  description: The SiliconFlow REST API
  version: "1.0.0"
  contact:
    name: SiliconFlow Support
    url: https://www.siliconflow.cn/
  license:
    name: MIT
    url: https://github.com/siliconflow/siliconcloud/blob/main/LICENSE
servers:
  - url: https://api.siliconflow.cn/v1
security:
  - bearerAuth: []


paths:
  /user/info:
    get:
      summary: Get user information
      operationId: user-info
      description: Get user information including balance and status
      tags:
        - UserInfo
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  code:
                    type: integer
                    example: 20000
                  message:
                    type: string
                    example: OK
                  status:
                    type: boolean
                    example: true
                  data:
                    type: object
                    properties:
                      id:
                        type: string
                        example: "userid"
                      name:
                        type: string
                        example: "username"
                        description: This field will no longer be returned after June 11th, and a fixed empty string will be output instead.
                      image:
                        type: string
                        example: "user_avatar_image_url"
                        description: This field will no longer be returned after June 11th, and a fixed empty string will be output instead.
                      email:
                        type: string
                        example: "user_email_address"
                        description: This field will no longer be returned after June 11th, and a fixed empty string will be output instead.
                      isAdmin:
                        type: boolean
                        example: false
                      balance:
                        type: string
                        example: "0.88"
                      status:
                        type: string
                        example: "normal"
                      introduction:
                        type: string
                        example: ""
                      role:
                        type: string
                        example: ""
                      chargeBalance:
                        type: string
                        example: "88.00"
                      totalBalance:
                        type: string
                        example: "88.88"
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '429':
          $ref: '#/components/responses/RateLimit'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false

  /models:
    get:
      summary: Get Model List
      operationId: Retrieve a list of models.
      description: Retrieve models information.
      parameters:
        - name: type
          in: query
          description: The type of models
          required: false
          schema:
            type: string
            enum: [ text, image, audio, video ]
        - name: sub_type
          in: query
          description: The sub type of models. You can use it to filter models individually without setting type.
          required: false
          schema:
            type: string
            enum: [ chat, embedding, reranker, text-to-image, image-to-image,  speech-to-text, text-to-video ]
      tags:
        - Models
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  object:
                    type: string
                    example: list
                  data:
                    type: array
                    items:
                      type: object
                      properties:
                        id:
                          type: string
                          example: stabilityai/stable-diffusion-xl-base-1.0
                        object:
                          type: string
                          example: model
                        created:
                          type: integer
                          example: 0
                        owned_by:
                          type: string
                          example: ""
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '429':
          $ref: '#/components/responses/RateLimit'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false

  /files:
    post:
      summary: Upload Files
      description: Upload files
      operationId: UploadFiles
      parameters: []
      requestBody:
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                purpose:
                  type: string
                  example: "batch"
                  enum: [
                    "batch"
                  ]
                file:
                    title: File upload
                    type: string
                    format: binary
                    example: /path/to/abc.jsonl
                    description: "File to upload"
              required:
                  - purpose
                  - file
 
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  code:
                    type: integer
                    example: 20000
                  message:
                    type: string
                    example: Ok
                  status:
                    type: boolean
                    example: true
                  data:
                    type: object
                    properties:
                      id:
                        type: string
                        example: file-jkvytbjtow
                      object:
                        type: string
                        example: file
                      bytes:
                        type: integer
                        example: 8509
                      createdAt:
                        type: integer
                        example: 1741685396
                      filename:
                        type: string
                        example: requests.jsonl
                      purpose:
                        type: string
                        example: batch

        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false

    get:
      summary: Returns a list of files.
      description: Returns a list of files.
      operationId: getFiles
      parameters:
        - name: purpose
          in: query
          required: true
          schema:
            type: string
            enum: [batch]  # 假设用途类型为枚举值
          description: Filter files by their purpose
        - name: limit
          in: query
          required: false
          schema:
            type: integer
            minimum: 1
            default: 10
          description: Maximum number of files to return (default 10)
      responses:
        '200':
          description: Successful response with file list
          content:
            application/json:
              schema:
                type: object
                properties:
                  code:
                    type: integer
                    example: 20000
                  message:
                    type: string
                    example: "Ok"
                  status:
                    type: boolean
                    example: true
                  data:
                    type: object
                    properties:
                      data:
                        type: array
                        items:
                          type: object
                          properties:
                            id:
                              type: string
                              example: "file-kkhtqklcnm"
                            object:
                              type: string
                              example: "file"
                            bytes:
                              type: integer
                              example: 806
                            created_at:
                              type: integer
                              example: 1741777570
                            filename:
                              type: string
                              example: "requests-2.jsonl"
                            purpose:
                              type: string
                              example: "batch"
                            line_count:
                              type: integer
                              example: 2
                      object:
                        type: string
                        example: "file"
                required:
                  - code
                  - message
                  - status
                  - data

        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false

  /batches:
    post:
      summary: Upload Files
      description: Upload files
      operationId: UploadFiles
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input_file_id:
                  type: string
                  example: file-jkvytbjtow
                  description: The ID of an uploaded file that contains requests for the new batch.
                endpoint:
                  type: string
                  example: /v1/chat/completions
                  description: The endpoint to be used for all requests in the batch. Currently /v1/chat/completions is supported. 
                completion_window:
                  type: string
                  example: 24h
                  description: The time frame within which the batch should be processed. The maximum value is 24 hours, and  the minimum value is 336 hours.
                metadata:
                  type: object
                  description: Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format, and querying for objects via API or the dashboard.<\br>Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.
                  properties:
                    description: 
                      type: string
                      example: nightly eval job
                replace:
                  type: object
                  properties:
                    model:
                      type: string
                      example: deepseek-ai/DeepSeek-V3
                      description:   For a complete list of available models, please check the [batches](/cn/userguide/guides/batch#3).
              required:
                - input_file_id
                - completion_window
                - endpoint

      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  id:
                    type: string
                    example: batch_rdyqgrcgjg
                  object:
                    type: string
                    example: batch
                  endpoint:
                    type: string
                    example: /v1/chat/completions
                  errors:
                    type: array
                    items:
                      type: string
                    example: null
                  input_file_id:
                    type: string
                    example: file-jkvytbjtow
                  completion_window:
                    type: string
                    example: 24h
                  status:
                    type: string
                    example: in_queue
                  output_file_id:
                    type: string
                    example: null
                  error_file_id:
                    type: string
                    example: null
                  created_at:
                    type: integer
                    example: 1741685413
                  in_progress_at:
                    type: integer
                    example: null
                  expires_at:
                    type: integer
                    example: 1741771813
                  finalizing_at:
                    type: integer
                    example: null
                  completed_at:
                    type: integer
                    example: null
                  failed_at:
                    type: integer
                    example: null
                  expired_at:
                    type: integer
                    example: null
                  cancelling_at:
                    type: integer
                    example: null
                  cancelled_at:
                    type: integer
                    example: null
                  request_counts:
                    type: object
                    example: null
                  metadata:
                    type: object
                    properties:
                      description:
                        type: string
                        example: nightly eval job

        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false
    get:
      summary: List your organization's batches.
      operationId: getBatchEvaluationJob
      description: List your organization's batches.
      parameters: 
        - name: limit
          in: query
          required: false
          schema:
            type: integer
            minimum: 1
          description: A limit on the number of objects to be returned. 
        - name: after
          in: query
          required: false
          schema:
            type: string
          description: A cursor for use in pagination. after is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  object:
                    type: string
                    example: "list"
                  data:
                    type: array
                    items:
                      type: object
                      properties:
                        id:
                          type: string
                          example: "batch_id"
                        object:
                          type: string
                          example: "batch"
                        endpoint:
                          type: string
                          example: "/v1/chat/completions"
                        errors:
                          type: array
                          nullable: true
                          items:
                            type: string
                          example: null
                        input_file_id:
                          type: string
                          example: "file-id"
                        completion_window:
                          type: string
                          example: "24h"
                        status:
                          type: string
                          example: "in_queue"
                        output_file_id:
                          type: string
                          nullable: true
                          example: null
                        error_file_id:
                          type: string
                          nullable: true
                          example: null
                        created_at:
                          type: integer
                          example: 1749023566
                        in_progress_at:
                          type: integer
                          nullable: true
                          example: null
                        expires_at:
                          type: integer
                          example: 1749109966
                        finalizing_at:
                          type: integer
                          nullable: true
                          example: null
                        completed_at:
                          type: integer
                          nullable: true
                          example: null
                        failed_at:
                          type: integer
                          nullable: true
                          example: null
                        expired_at:
                          type: integer
                          nullable: true
                          example: null
                        cancelling_at:
                          type: integer
                          nullable: true
                          example: null
                        cancelled_at:
                          type: integer
                          nullable: true
                          example: null
                        request_counts:
                          type: object
                          nullable: true
                          example: null
                        metadata:
                          type: object
                          properties:
                            batch_description:
                              type: string
                              example: ""
                            name:
                              type: string
                              example: "batch"
                        file_name:
                          type: string
                          example: "requests_name.json"
                  first_id:
                    type: string
                    example: "first_batch_id"
                  last_id:
                    type: string
                    example: "last_batch_id"
                  has_more:
                    type: boolean
                    example: false

        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false


  /batches/{batch_id}:
    get:
      summary: Retrieves a batch.
      operationId: getBatchEvaluationJob
      description: Retrieves a batch.
      parameters:
        - name: batch_id
          in: path
          description: The ID of the batch to retrieve.
          required: true
          schema:
            type: string
      responses:
        '200':
          description: The Batch object matching the specified ID.
          content:
            application/json:
              schema:
                type: object
                properties:
                  id:
                    type: string
                    example: batch_rdyqgrcgjg
                  object:
                    type: string
                    example: batch
                  endpoint:
                    type: string
                    example: /v1/chat/completions
                  errors:
                    type: array
                    items:
                      type: string
                    example: []
                  input_file_id:
                    type: string
                    example: file-jkvytbjtow
                  completion_window:
                    type: string
                    example: 24h
                  status:
                    type: string
                    example: in_queue
                  output_file_id:
                    type: string
                    example: null
                  error_file_id:
                    type: string
                    example: null
                  created_at:
                    type: integer
                    example: 1741685413
                  in_progress_at:
                    type: integer
                    example: null
                  expires_at:
                    type: integer
                    example: 1741771813
                  finalizing_at:
                    type: integer
                    example: null
                  completed_at:
                    type: integer
                    example: null
                  failed_at:
                    type: integer
                    example: null
                  expired_at:
                    type: integer
                    example: null
                  cancelling_at:
                    type: integer
                    example: null
                  cancelled_at:
                    type: integer
                    example: null
                  request_counts:
                    type: object
                    example: {}
                  metadata:
                    type: object
                    properties:
                      description:
                        type: string
                        example: nightly eval job
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized' 
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false


  /batches/{batch_id}/cancel:
    post:
      summary: Cancel a specific batch
      description: This endpoint cancels a batch identified by its unique ID.
      operationId: cancelBatch
      parameters:
        - name: batchId
          in: path
          required: true
          schema:
            type: string
          description: Unique identifier of the batch to cancel

      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  id:
                    type: string
                    example: batch_rdyqgrcgjg
                  object:
                    type: string
                    example: batch
                  endpoint:
                    type: string
                    example: /v1/chat/completions
                  errors:
                    type: array
                    items:
                      type: string
                    example: null
                  input_file_id:
                    type: string
                    example: file-jkvytbjtow
                  completion_window:
                    type: string
                    example: 24h
                  status:
                    type: string
                    example: in_queue
                  output_file_id:
                    type: string
                    example: null
                  error_file_id:
                    type: string
                    example: null
                  created_at:
                    type: integer
                    example: 1741685413
                  in_progress_at:
                    type: integer
                    example: null
                  expires_at:
                    type: integer
                    example: 1741771813
                  finalizing_at:
                    type: integer
                    example: null
                  completed_at:
                    type: integer
                    example: null
                  failed_at:
                    type: integer
                    example: null
                  expired_at:
                    type: integer
                    example: null
                  cancelling_at:
                    type: integer
                    example: null
                  cancelled_at:
                    type: integer
                    example: null
                  request_counts:
                    type: object
                    example: null
                  metadata:
                    type: object
                    properties:
                      description:
                        type: string
                        example: nightly eval job

        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false


  /uploads/audio/voice:
    post:
      summary: Upload Voice
      description: >
         Upload user-provided voice style, which can be in base64 encoding or file format. Refer to (https://docs.siliconflow.cn/capabilities/text-to-speech#2-2)
      operationId: uploadAudioVoice
      parameters: []
      requestBody:
        content:
          multipart/form-data:
            schema:
              type: object
              properties:
                model:
                  type: string
                  example: FunAudioLLM/CosyVoice2-0.5B
                  enum: 
                    - FunAudioLLM/CosyVoice2-0.5B
                  description: "Predefined voice style model name"
                customName:
                  type: string
                  example: "your-voice-name"
                  description: "User-defined voice style name"
                text:
                  type: string
                  example: "在一无所知中, 梦里的一天结束了，一个新的轮回便会开始"
                  description: "Corresponding text content for the audio"
              required:
                - model
                - customName
                - text
              oneOf:
                - properties:
                    audio:
                      title: Base64 encoding of audio
                      type: string
                      example: "data:audio/mpeg;base64,aGVsbG93b3JsZA=="
                      description: "Audio file encoded in base64 with the header format of `data:audio/mpeg;base64`"
                - properties:
                    file:
                      title: File upload for audio
                      type: string
                      format: binary
                      example: /path/to/audio.mp3
                      description: "File to upload"
         
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  uri:
                    type: string
                    example: 'speech:your-voice-name:xxx:xxx'
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '429':
          $ref: '#/components/responses/RateLimit'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false


  /chat/completions:
    post:
      summary: Chat Completions
      operationId: chat-completions
      description: Creates a model response for the given chat conversation.
      tags:
        - Chat Completions
      requestBody:
        content:
          application/json:
            schema:
              oneOf:
                - $ref: "#/components/schemas/ChatCompletionRequest"
                - $ref: "#/components/schemas/ChatCompletionVLMRequest"
                
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ChatCompletionResponse"
            text/event-stream:
              schema:
                $ref: "#/components/schemas/ChatCompletionStream"
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '429':
          $ref: '#/components/responses/RateLimit'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false

  /embeddings:
    post:
      summary: Create Embeddings
      description: Creates an embedding vector representing the input text.
      operationId: createEmbedding
      tags:
        - Embeddings
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/EmbeddingsRequest'
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EmbeddingsResponse'
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '429':
          $ref: '#/components/responses/RateLimit'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false

  /audio/speech:
    post:
      operationId: createSpeech
      tags:
          - Audio
      summary: Create Speech
      description: Generate audio from input text. The data generated by the interface is the binary data of the audio, which requires the user to handle it themselves. Reference:https://docs.siliconflow.cn/capabilities/text-to-speech#5 
      requestBody:
          required: true
          content:
              application/json:
                  schema:
                    oneOf:  
                      - $ref: "#/components/schemas/MOSS-TTSD-v0.5"
                      - $ref: "#/components/schemas/CosyVoice2-0.5B"
                      # - $ref: "#/components/schemas/IndexTTS-2"


      responses:
          "200":
              description: Generate audio based on the input text. The data generated by the interface is in binary format and requires the user to process it themselves. Reference:https://docs.siliconflow.cn/capabilities/text-to-speech#5
              headers:
                  Transfer-Encoding:
                      schema:
                          type: string
                      description: chunked
              content:
                  application/audio:
                      schema:
                          type: string
                          format: binary
                          example: 音频的二进制数据
                  audio/wav:
                      schema:
                          type: string
                          format: binary
                          example: 音频的二进制数据
                  audio/opus:
                      schema:
                          type: string
                          format: binary
                          example: 音频的二进制数据
          '400':
            $ref: '#/components/responses/BadRequest'
          '401':
            $ref: '#/components/responses/Unauthorized'
          '403':
            $ref: '#/components/responses/Forbidden'
          '404':
            $ref: '#/components/responses/NotFound'
          '429':
            $ref: '#/components/responses/RateLimit'
          '503':
            $ref: '#/components/responses/Overloaded'
          '504':
            $ref: '#/components/responses/Timeout'

  /audio/voice/list:
    get:
      summary: Get Voice List
      description: Get list of user-defined voice styles
      operationId: audioVoiceList
      tags:
        - Audio
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                description: "User-defined voice style list response"
                properties:
                  results:
                    type: array
                    description: "Predefined voice style list"
                    items:
                      type: object
                      properties:
                        model:
                          type: string
                          example: "fishaudio/fish-speech-1.4"
                          description: "Predefined voice style model name"
                        customName:
                          type: string
                          example: "your-voice-name"
                          description: "User-defined voice style name"
                        text:
                          type: string
                          example: "在一无所知中, 梦里的一天结束了，一个新的轮回便会开始"
                          description: "Corresponding text content for the audio"
                        uri:
                          type: string
                          example: "speech:your-voice-name:xxx:xxx"
                          description: "URI generated after uploading the audio"
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '429':
          $ref: '#/components/responses/RateLimit'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'


  /audio/voice/deletions:
    post:
      tags:
        - Audio
      summary: Delete User Voice
      description: Delete user-defined voice style
      operationId: AudioVoiceDeletions
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                uri:
                  type: string
                  example: "speech:your-voice-name:xxx:xxxx"
                  description: "Voice style to be deleted by the user"
              required:
                - uri

      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: string
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '429':
          $ref: '#/components/responses/RateLimit'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false  
      
  /audio/transcriptions:
    post:
      summary: Create Audio Transcriptions
      description: Creates an audio transcription.
      operationId: createAudioTranscriptions
      tags:
        - Audio
      requestBody:
        content:
          #multipart/form-data; boundary=<calculated when request is sent>:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AudioRequest'
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AudioResponse'
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '429':
          $ref: '#/components/responses/RateLimit'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false

  /rerank:
    post:
      summary: Create Rerank
      description: Creates a rerank request.
      operationId: createRerank
      tags:
        - Rerank
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RerankRequest'
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RerankResponse'
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '429':
          $ref: '#/components/responses/RateLimit'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false

  /images/generations:
    post:
      summary: Image Generation
      operationId: ImageGeneration
      description: Creates an image response for the given prompt. The URL for the generated image is valid for one hour. Please make sure to download and store it promptly to avoid any issues due to URL expiration.
      tags:
        - Image
      requestBody:
        content:
          application/json:
            schema:
              oneOf:
                - $ref: "#/components/schemas/Kolors"

                

      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImagesGenerationResponse"
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '429':
          $ref: '#/components/responses/RateLimit'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false

  /video/submit:
    post:
      summary: Submit video
      description: Generate a video through the input prompt. This API returns the user's current request ID. The user needs to poll the status interface to get the specific video link. The generated result is valid for 10 minutes, so please retrieve the video link promptly.
      tags:
        - Video
      requestBody:
        content:
          application/json:
            schema:
              oneOf:
                - $ref: "#/components/schemas/I2V" 
                
                


      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties: 
                  requestId:
                    type: string
                    description: The requestId generated by this request needs to be used when calling the status interface.
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '429':
          $ref: '#/components/responses/RateLimit'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'


  /video/status:
    post:
      summary: get video
      description: Get the user-generated video. The URL for the generated video is valid for one hour. Please make sure to download and store it promptly to avoid any issues due to URL expiration.
      tags:
        - video
      requestBody:
        content:
          application/json:
            schema:
              oneOf:
                - $ref: "#/components/schemas/getVideosRequest"

      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/getVideosResponse"
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false

  /messages:
    post:
      summary: Chat Completions
      operationId: chat-completions
      description: Creates a model response for the given chat conversation.
      tags:
        - messages
      security:
        - bearerAuth: []
        - apiKey: []
      requestBody:
        content:
          application/json:
            schema:
              oneOf:
                - $ref: "#/components/schemas/ChatMessagesRequest"
                
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/MessgesResponse"
        '400':
          $ref: '#/components/responses/BadRequest'
        '401':
          $ref: '#/components/responses/Unauthorized'
        '403':
          $ref: '#/components/responses/Forbidden'
        '404':
          $ref: '#/components/responses/NotFound'
        '429':
          $ref: '#/components/responses/RateLimit'
        '503':
          $ref: '#/components/responses/Overloaded'
        '504':
          $ref: '#/components/responses/Timeout'
      deprecated: false



components:
  securitySchemes:
    # 方式2：API Key（x-api-key）
    apiKey:
      type: apiKey
      in: header
      name: x-api-key
      description: "Use the following format for authentication: [<your api key>](https://cloud.siliconflow.cn/account/ak)"
    bearerAuth:
      type: http
      scheme: bearer 
      bearerFormat: "your api key"
      description: "Use the following format for authentication: Bearer [<your api key>](https://cloud.siliconflow.cn/account/ak)"

  responses:
    BadRequest:
      description: 'BadRequest'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/BadRquestData'
    Unauthorized:
      description: 'Unauthorized'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/UnauthorizedData'
    Forbidden:
      description: 'Forbidden'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ForbiddenData'
    NotFound:
      description: 'NotFound'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/NotFoundData'
    RateLimit:
      description: 'RateLimit'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/RateLimitData'
    Overloaded:
      description: 'Overloaded'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/OverloadedtData'
    Timeout:
      description: 'Timeout'
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/TimeoutData'

  schemas:
    EmbeddingsRequest:
      type: object
      required:
        - model
        - input
      properties:
        model:
          type: string
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.  **For a complete list of available models, please check the [Models](https://cloud.siliconflow.cn/sft-d29cs9gh3vvc73c59kb0/models?types=embedding)**.
          example: BAAI/bge-large-zh-v1.5
          default: BAAI/bge-large-zh-v1.5
          enum:
            - BAAI/bge-large-zh-v1.5
            - netease-youdao/bce-embedding-base_v1
            - Pro/BAAI/bge-m3
            - Qwen/Qwen3-Embedding-8B
            - Qwen/Qwen3-Embedding-4B
        input:
          description: |
            Input text to embed must be provided as a string or an array of tokens. To process multiple inputs in a single request, pass an array of strings or an array of token arrays. The input length must not exceed the model's maximum token limit and should not be an empty string.
            The maximum input tokens for each model are as follows:

            BAAI/bge-large-zh-v1.5, BAAI/bge-large-en-v1.5, netease-youdao/bce-embedding-base_v1: 512
            BAAI/bge-m3, Pro/BAAI/bge-m3: 8192
            Qwen/Qwen3-Embedding-8B, Qwen/Qwen3-Embedding-4B, Qwen/Qwen3-Embedding-0.6B: 32768
          default: "Silicon flow embedding online: fast, affordable, and high-quality embedding services. come try it out!"
          oneOf:
            - type: string
              title: string
              description: The string that will be turned into an embedding. the item must not exceed the max models tokens limitation.
              default: "Silicon flow embedding online: fast, affordable, and high-quality embedding services. come try it out!"
              example: "Silicon flow embedding online: fast, affordable, and high-quality embedding services. come try it out!"
            - type: array
              title: array
              description: |
                The array of strings that will be turned into an embedding. The array length must not exceed the max size, and the item must not exceed the max models tokens limitation.
                Current, the maximum array size is 32 , At the same time every item must not exceed 512 tokens for current models.
              minItems: 1
              maxItems: 32
              items:
                type: string
                default: "['LLM', 'Embedding', 'RAG']"
                example: "['LLM', 'Embedding', 'RAG']"
        encoding_format:
          description: |
            "The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/). "
          example: "float"
          default: "float"
          type: string
          enum: [ "float", "base64" ]
        dimensions:
          description: >
            The number of dimensions the resulting output embeddings should have. Only supported in
            `Qwen/Qwen3` series. 
            - Qwen/Qwen3-Embedding-8B: [64,128,256,512,768,1024,1536,2048,2560,4096]
            -  Qwen/Qwen3-Embedding-4B:[64,128,256,512,768,1024,1536,2048,2560]
            - Qwen/Qwen3-Embedding-0.6B: [64,128,256,512,768,1024]
          type: integer
          example: 1024

    ChatMessagesRequest:
      title: LLM
      type: object
      required:
        - model
        - messages
        - max_tokens
      properties:
        model:
          type: string
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.**For a complete list of available models, please check the [Models](https://cloud.siliconflow.cn/sft-d29cs9gh3vvc73c59kb0/models?types=chat)**.
          example: Pro/zai-org/GLM-4.7
          default: 
          enum:
            - Pro/zai-org/GLM-4.7
            - Pro/deepseek-ai/DeepSeek-V3.2        
            - Pro/moonshotai/Kimi-K2-Instruct-0905
            - moonshotai/Kimi-Dev-72B
            - baidu/ERNIE-4.5-300B-A47B
        messages:
          type: array
          description: A list of messages comprising the conversation so far.
          items:
            type: object
            properties:
              role:
                type: string
                description: 'The role of the messages author. Choice between: system, user.'
                example: user
                enum:
                  - user
                  - system
                  - assistant
              content:
                oneOf:
                  - type: string
                    description: The contents of the message.
                    example: What opportunities and challenges will the Chinese large model industry face in 2025?
            required:
              - role
              - content
          minItems: 1
          maxItems: 10
        system:
          allOf:
            - anyOf:
                - type: string
                - items:
                    $ref: '#/components/schemas/RequestTextBlock'
                  type: array
              description: >-
                System prompt.


                A system prompt is a way of providing context and
                instructions to llm, such as specifying a particular
                goal or role. 
              title: System
        
        stop_sequences:
          allOf:
            - description: >-
                Custom text sequences that will cause the model to stop
                generating.


                Our models will normally stop when they have naturally
                completed their turn, which will result in a response
                `stop_reason` of `"end_turn"`.


                If you want the model to stop generating when it
                encounters custom strings of text, you can use the
                `stop_sequences` parameter. If the model encounters one of
                the custom sequences, the response `stop_reason` value
                will be `"stop_sequence"` and the response `stop_sequence`
                value will contain the matched stop sequence.
              items:
                type: string
              title: Stop Sequences
              type: array
        stream:
          type: boolean
          description: "If set, tokens are returned as Server-Sent Events as they are made available. Stream terminates with `data: [DONE]`"
          example: true
        max_tokens:
          type: integer
          description: >-
                        The maximum number of tokens to generate before stopping.


                        Note that our models may stop _before_ reaching this
                        maximum. This parameter only specifies the absolute
                        maximum number of tokens to generate.


                        Different models have different maximum values for this
                        parameter.  See
                        [models](https://docs.siliconflow.cn/cn/userguide/capabilities/text-generation)
                        for details.
          example: 8192
        temperature:
          type: number
          description: Determines the degree of randomness in the response.
          format: float
          example: 0.7
          maximum: 2
          minimum: 0
        top_p:
          type: number
          description: The `top_p` (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.
          format: float
          example: 0.7
          minimum: 0.1
          maximum: 1  
        top_k:
          type: number
          format: float
          example: 50
          minimum: 0
          maximum: 50 
        tools:
          type: array
          description: >
                    Each tool definition includes:


                      * `name`: Name of the tool.

                      * `description`: Optional, but strongly-recommended
                      description of the tool.

                      * `input_schema`: [JSON
                      schema](https://json-schema.org/draft/2020-12) for the
                      tool `input` shape that the model will produce in
                      `tool_use` output content blocks.
          items:
            $ref: "#/components/schemas/MessagesTool"
        tool_choice:
          allOf:
            - description: >-
                How the model should use the provided tools. The model can
                use a specific tool, any available tool, decide by itself,
                or not use tools at all.
              discriminator:
                mapping:
                  auto: '#/components/schemas/ToolChoiceAuto'
                  none: '#/components/schemas/ToolChoiceNone'
                  tool: '#/components/schemas/ToolChoiceTool'
                propertyName: type
              oneOf:
                - $ref: '#/components/schemas/ToolChoiceAuto'
                - $ref: '#/components/schemas/ToolChoiceTool'
                - $ref: '#/components/schemas/ToolChoiceNone'

    RequestTextBlock:
      additionalProperties: false
      properties:
        text:
          minLength: 1
          title: Text
          type: string
        type:
          enum:
            - text
          title: Type
          type: string
      required:
        - text
        - type
      title: Text
      type: object


    ToolChoiceAny:
      additionalProperties: false
      description: The model will use any available tools.
      properties:
        disable_parallel_tool_use:
          description: >-
            Whether to disable parallel tool use.


            Defaults to `false`. If set to `true`, the model will output exactly
            one tool use.
          title: Disable Parallel Tool Use
          type: boolean
        type:
          enum:
            - any
          title: Type
          type: string
      required:
        - type
      title: Any
      type: object
    ToolChoiceAuto:
      additionalProperties: false
      description: The model will automatically decide whether to use tools.
      properties:
        disable_parallel_tool_use:
          description: >-
            Whether to disable parallel tool use.


            Defaults to `false`. If set to `true`, the model will output at most
            one tool use.
          title: Disable Parallel Tool Use
          type: boolean
        type:
          enum:
            - auto
          title: Type
          type: string
      required:
        - type
      title: Auto
      type: object
    ToolChoiceNone:
      additionalProperties: false
      description: The model will not be allowed to use tools.
      properties:
        type:
          enum:
            - none
          title: Type
          type: string
      required:
        - type
      title: None
      type: object
    ToolChoiceTool:
      additionalProperties: false
      description: The model will use the specified tool with `tool_choice.name`.
      properties:
        disable_parallel_tool_use:
          description: >-
            Whether to disable parallel tool use.


            Defaults to `false`. If set to `true`, the model will output exactly
            one tool use.
          title: Disable Parallel Tool Use
          type: boolean
        name:
          description: The name of the tool to use.
          title: Name
          type: string
        type:
          enum:
            - tool
          title: Type
          type: string
      required:
        - name
        - type
      title: Tool
      type: object


    EmbeddingsResponse:
      type: object
      required:
        - object
        - model
        - data
        - usage
      properties:
        object:
          type: string
          description: The object type, which is always "list".
          enum:
            - [ list ]
        model:
          description: The name of the model used to generate the embedding.
          type: string
        data:
          type: array
          description: The list of embeddings generated by the model.
          items:
            type: object
            required: [ index, object, embedding ]
            properties:
              object:
                type: string
                enum:
                  - embedding
              embedding:
                type: array
                items:
                  type: number
              index:
                type: integer
        usage:
          type: object
          description: The usage information for the request.
          properties:
            prompt_tokens:
              type: integer
              description: The number of tokens used by the prompt.
            completion_tokens:
              type: integer
              description: The number of tokens used by the completion.
            total_tokens:
              type: integer
              description: The total number of tokens used by the request.
          required:
            - prompt_tokens
            - total_tokens
            - completion_tokens

    RerankRequest:
      type: object
      required:
        - model
        - query
        - documents
      properties:
        model:
          type: string
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.  **For a complete list of available models, please check the [Models](https://cloud.siliconflow.cn/sft-d29cs9gh3vvc73c59kb0/models?types=rerank)**.
          example: BAAI/bge-reranker-v2-m3
          enum:
            - Qwen/Qwen3-Reranker-8B
            - Qwen/Qwen3-Reranker-4B
            - Qwen/Qwen3-Reranker-0.6B
            - BAAI/bge-reranker-v2-m3
            - Pro/BAAI/bge-reranker-v2-m3
            - netease-youdao/bce-reranker-base_v1
        instruction:
          type: string
          description: The instruction for the reranker, only support Qwen/Qwen3-Reranker-8B, Qwen/Qwen3-Reranker-4B,Qwen/Qwen3-Reranker-0.6B.         
          example: "Please rerank the documents based on the query."
        query:
          type: string
          description: Required. The search query.
          example: Apple
        documents:
          type: array
          minItems: 1
          items:
            type: string
          description: Currently, only string lists are supported. Document objects will be supported in the future.
          example: ["apple", "banana", "fruit", "vegetable" ]
          default: [ "apple", "banana", "fruit", "vegetable" ]
        top_n:
          type: integer
          example: 4
          description: Number of most relevant documents or indices to return.
        return_documents:
          type: boolean
          description: If false, the response does not include document text; if true, it includes the input document text.
        max_chunks_per_doc:
          type: integer
          description: Maximum number of chunks generated from within a document. Long documents are divided into multiple chunks for calculation, and the highest score among the chunks is taken as the document's score. only BAAI/bge-reranker-v2-m3, Pro/BAAI/bge-reranker-v2-m3, netease-youdao/bce-reranker-base_v1 support this field.
        overlap_tokens:
          type: integer
          maximum: 80
          description: Number of token overlaps between adjacent chunks when documents are chunked. only BAAI/bge-reranker-v2-m3, Pro/BAAI/bge-reranker-v2-m3, netease-youdao/bce-reranker-base_v1 support this field.


    RerankResponse:
      type: object
      required:
        - id
        - results
        - tokens
      properties:
        id:
          type: string
        results:
          type: array
          items:
            type: object
            properties:
              document:
                type: object
                properties:
                  text:
                    type: string
                description: Original document content.
              index:
                type: integer
                description: The index value of the position in the input candidate doc array.
              relevance_score:
                type: number
                description: Similarity score.
        tokens:
          type: object
          properties:
            input_tokens:
              type: integer
            output_tokens:
              type: integer


    AudioRequest:
      type: object
      required:
        - model
        - file
      properties:
        file:
          type: string
          description: The audio file object (not file name) to transcribe
          example: /path/to/file/audio.mp3
          format: binary
        model:
          type: string
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
          example: FunAudioLLM/SenseVoiceSmall
          enum:
            - FunAudioLLM/SenseVoiceSmall
            - TeleAI/TeleSpeechASR

    AudioResponse:
      type: object
      description: Represents a transcription response returned by model, based on the provided input.
      required:
        - text
      properties:
        text:
          description: The transcribed text.
          type: string


    StringData:
      type: string
    ErrorData:
      type: object
      required:
        - error
      properties:
        error:
          type: object
          properties:
            message:
              type: string
              nullable: false
            type:
              type: string
              nullable: false
            param:
              type: string
              nullable: true
              default: null
            code:
              type: string
              nullable: true
              default: null
          required:
            - type
            - message
            - param
            - code
      
    SuccessfulResponse:
      type: object
      required:
        - requestId
      properties:
        requestId:
          type: integer
          nullable: true   
    BadRquestData:
      type: object
      required:
        - message
        - data
        - code
      properties:
        code:
          type: integer
          nullable: true
          default: false
          example: 20012
        message:
          type: string
          nullable: false
        data:
          type: string
          nullable: false
    UnauthorizedData:
      type: string
      default: false
      example: Invalid token
    ForbiddenData:
      type: string
      default: false
      example: Forbidden
    NotFoundData:
      type: string
      default: false
      example: 404 page not found
    RateLimitData:
      type: object
      required:
        - message
        - data
      properties:
        message:
          type: string
          example: Request was rejected due to rate limiting. If you want more, please contact contact@siliconflow.cn. Details:TPM limit reached.
        data:
          type: string
    OverloadedtData:
      type: object
      required:
        - code
        - message
        - data
      properties:
        code:
          type: integer
          example: 50505
        message:
          type: string
          example: Model service overloaded. Please try again later.
        data:
          type: string
          nullable: false
    TimeoutData:
      type: string




    FinishReason:
      type: string
      enum:
        - stop
        - eos
        - length
        - tool_calls

    LogprobsPart:
      type: object
      properties:
        tokens:
          type: array
          items:
            type: string
          description: List of token strings
        token_logprobs:
          type: array
          items:
            type: number
            format: float
          description: List of token log probabilities

    PromptPart:
      type: array
      items:
        type: object
        properties:
          text:
            type: string
            example: <s>[INST] What is the capital of France? [/INST]
            default: <s>[INST] What is the capital of France? [/INST]
          logprobs:
            $ref: "#/components/schemas/LogprobsPart"

    UsageData:
      type: object
      properties:
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt.
        completion_tokens:
          type: integer
          description: Number of tokens in the generated completion.
        total_tokens:
          type: integer
          description: Total number of tokens used in the request (prompt + completion).
        prompt_cache_hit_tokens:
          type: integer
          description: The number of tokens in the input of this request that resulted in a cache hit.
        prompt_cache_miss_tokens:
          type: integer
          description: The number of tokens in the input of this request that did not result in a cache hit.
        completion_tokens_details:
          type: object
          description: Breakdown of tokens used in a completion.
          properties:
            reasoning_tokens:
              type: integer
              default: 0
              description: Tokens generated by the model for reasoning.
        prompt_tokens_details:
          type: object
          description: Breakdown of tokens used in the prompt.
          properties:
            cached_tokens:
              type: integer
              default: 0
              description: Cached tokens present in the prompt.        
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens


    CompletionChoicesData:
      type: array
      items:
        type: object
        properties:
          text:
            type: string
          finish_reason:
            $ref: "#/components/schemas/FinishReason"
          logprobs:
            allOf:
              - $ref: "#/components/schemas/LogprobsPart"
              - nullable: true

    CompletionResponse:
      type: object
      properties:
        id:
          type: string
        choices:
          $ref: "#/components/schemas/CompletionChoicesData"
        prompt:
          $ref: "#/components/schemas/PromptPart"
        usage:
          $ref: "#/components/schemas/UsageData"
        created:
          type: integer
        model:
          type: string
        object:
          type: string
          enum:
            - text_completion
      required:
        - id
        - choices
        - usage
        - created
        - model
        - object

    CompletionStream:
      oneOf:
        - $ref: "#/components/schemas/CompletionEvent"

    CompletionEvent:
      type: object
      required: [ data ]
      properties:
        data:
          $ref: "#/components/schemas/CompletionChunk"

    CompletionChunk:
      type: object
      required: [ id, token, choices, usage, finish_reason ]
      properties:
        id:
          type: string
        token:
          $ref: "#/components/schemas/CompletionToken"
        choices:
          title: CompletionChoices
          type: array
          items:
            $ref: "#/components/schemas/CompletionChoice"
        tool_calls:
          type: array
          items:
              $ref: "#/components/schemas/ChatCompletionMessageToolCallChunk"
        usage:
          allOf:
            - $ref: "#/components/schemas/UsageData"
            - nullable: true
        finish_reason:
          allOf:
            - $ref: "#/components/schemas/FinishReason"
            - nullable: true

    ChatCompletionMessageToolCallChunk:
      type: object
      properties:
          index:
              type: integer
          id:
              type: string
              description: The ID of the tool call.
          type:
              type: string
              enum: ["function"]
              description: The type of the tool. Currently, only `function` is supported.
          function:
              type: object
              properties:
                  name:
                      type: string
                      description: The name of the function to call.
                  arguments:
                      type: string
                      description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
      required:
          - index    

    CompletionChoice:
      type: object
      required: [ index ]
      properties:
        text:
          type: string

    CompletionToken:
      type: object
      required: [ id, text, logprob, special ]
      properties:
        id:
          type: integer
        text:
          type: string
        logprob:
          type: number
          format: float
        special:
          type: boolean

    ChatCompletionChoicesData:
      type: array
      items:
        type: object
        properties:
          message:
            type: object
            properties:
              role:
                type: string
                example: assistant
              content:
                type: string
              reasoning_content: 
                description: Only the deepseek-R1 series and Qwen/QwQ-32B models support reasoning_content. This part returns the reasoning content, which is at the same level as the content. In each round of the conversation, the model outputs the reasoning chain content (reasoning_content) and the final answer (content). In the next round of the conversation, the reasoning chain content from previous rounds will not be appended to the context.
                type: string
              tool_calls:
                type: array
                description: The tool calls generated by the model, such as function calls.
                items:
                    $ref: "#/components/schemas/ChatCompletionMessageToolCall"
          finish_reason:
            $ref: "#/components/schemas/FinishReason"

    ChatCompletionRequestMessageContentPartText:
      type: object
      title: Text
      properties:
        type:
          type: string
          enum: [ "text" ]
          description: The type of the content part.
          default: "text"
        text:
          type: string
          description: The text content.
          default: "Describe this picture."
      required:
        - type
        - text

    ChatCompletionRequestMessageContentPartImage:
      type: object
      title: Image
      properties:
        type:
          type: string
          enum: [ "image_url" ]
          description: The type of the image content part. deepseek-ai/DeepSeek-OCR 
          default: "image_url"
        image_url:
          type: object
          properties:
            url:
              type: string
              description: Either a URL of the image or the base64 encoded image data. For model `deepseek-ai/DeepSeek-OCR`, PDF files are also supported via URL or base64; other models accept images only. TeleAI/TeleMM only support the base64 encoded image data.
              example: "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/dog.png"
            detail:
              type: string
              description: Specifies the detail level of the image. For model `deepseek-ai/DeepSeek-OCR`, this field is not supported and uses fixed Base mode with 1024x1024 resolution.
              enum: [ "auto", "low", "high" ]
              default: "auto"
          required:
            - url
      required:
        - type
        - image_url

    ChatCompletionRequestMessageContentPartAudio:
      type: object
      title: Audio
      properties:
        type:
          type: string
          enum: [ "audio_url" ]
          description: The type of the audio content part.
          default: "audio_url"
        audio_url:
          type: object
          description: The audion url.
          properties:
            url:
              type: string
              description: Either a URL of the video or the base64 encoded video data. 
              example: "data:audio/mpeg;base64,"
          required:
            - url
      required:
        - type
        - video_url

    ChatCompletionRequestMessageContentPartVideo:
      type: object
      title: Video
      properties:
        type:
          type: string
          enum: [ "video_url" ]
          description: The type of the content part.
          default: "video_url"
        video_url:
          type: object
          properties:
            url:
              type: string
              description: Either a URL of the video or the base64 encoded video data. 
              example: "data:video/mp4;base64,"
            detail:
              type: string
              description: Specifies the detail level of the video.
              enum: [ "auto", "low", "high" ]
              default: "auto"
            max_frams:
              type: integer
              description: The upper limit for the total number of frames.
            fps:
              type: integer
              description: >
                The number of frames extracted per second from a video of length T seconds. The final number of frames is min(fps × T, max_frames). 
                For example:
                  - For a 10-second video with fps = 1 and max_frames = 8, the final number of frames is min(1 × 10, 8) = 8.
                  - For a 5-second video with fps = 2 and max_frames = 30, the final number of frames is min(2 × 5, 30) = 10.
          required:
            - url
      required:
        - type
        - video_url

    ChatCompletionRequestUserMessageContentPart:
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
        - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartImage"
        - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartAudio"
        - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartVideo"
      x-oaiExpandable: true

    ChatCompletionRequest:
      title: LLM
      type: object
      required:
        - model
        - messages
      properties:
        model:
          type: string
          description:  Corresponding Model Name. We periodically update our models to enhance service quality. Changes may include model on/offlining or capability adjustments. We will strive to notify you via announcements or push messages. **For a complete list of available models, please check the [Models](https://cloud.siliconflow.cn/sft-d29cs9gh3vvc73c59kb0/models?types=chat)**.
          example: Pro/zai-org/GLM-4.7
          enum:
            - Pro/zai-org/GLM-4.7
            - Pro/moonshotai/Kimi-K2-Thinking
            - moonshotai/Kimi-K2-Thinking
            - Kwaipilot/KAT-Dev
            - MiniMaxAI/MiniMax-M2
            - deepseek-ai/DeepSeek-V3.2-Exp
            - Pro/deepseek-ai/DeepSeek-V3.2-Exp
            - inclusionAI/Ling-1T
            - zai-org/GLM-4.6
            - moonshotai/Kimi-K2-Instruct-0905
 
        messages:
          type: array
          description: A list of messages comprising the conversation so far.
          items:
            type: object
            properties:
              role:
                type: string
                description: 'The role of the messages author. Choice between: system, user, or assistant.'
                example: user
                default: user
                enum:
                  - user
                  - assistant
                  - system
              content:
                oneOf:
                  - type: string
                    description: The contents of the message.
                    example: What opportunities and challenges will the Chinese large model industry face in 2025?
                    default: What opportunities and challenges will the Chinese large model industry face in 2025?
            required:
              - role
              - content
          minItems: 1
          maxItems: 10
        stream:
          type: boolean
          description: "If set, tokens are returned as Server-Sent Events as they are made available. Stream terminates with `data: [DONE]`"
          example: false
        max_tokens:
          type: integer
          description: >
            The maximum number of tokens to generate. Ensure that input tokens + max_tokens do not exceed the model’s context window. As some services are still being updated, avoid setting max_tokens to the window’s upper bound; reserve ~10k tokens as buffer for input and system overhead. See Models(https://cloud.siliconflow.cn/models) for details. 
          example: 4096
        enable_thinking:
          type: boolean
          description: >
            Switches between thinking and non-thinking modes. Default is True. 
            This field supports the following models: 
            
                - zai-org/GLM-4.6
                - Qwen/Qwen3-8B
                - Qwen/Qwen3-14B
                - Qwen/Qwen3-32B
                - wen/Qwen3-30B-A3B
                - Qwen/Qwen3-235B-A22B
                - tencent/Hunyuan-A13B-Instruct
                - zai-org/GLM-4.5V
                - deepseek-ai/DeepSeek-V3.1-Terminus
                - Pro/deepseek-ai/DeepSeek-V3.1-Terminus
            
            If you want to use the function call feature for deepseek-ai/DeepSeek-V3.1 or Pro/deepseek-ai/DeepSeek-V3.1 , you need to set enable_thinking to false. 
            
          example: false      
        thinking_budget:
          type: integer
          description: Maximum number of tokens for chain-of-thought output. This field applies to all Reasoning models.
          example: 4096
          default: 4096
          minimum: 128
          maximum: 32768
        min_p:
          type: number
          description: Dynamic filtering threshold that adapts based on token probabilities.This field only applies to Qwen3.
          format: float
          example: 0.05
          minimum: 0
          maximum: 1
        stop:
          description: >
            Up to 4 sequences where the API will stop generating further tokens.
            The returned text will not contain the stop sequence.
          nullable: true
          oneOf:
            - type: string
              example: null
              nullable: true
            - type: array
              minItems: 1
              maxItems: 4
              items:
                type: string
                example: "null"
        temperature:
          type: number
          description: Determines the degree of randomness in the response.
          format: float
          example: 0.7
        top_p:
          type: number
          description: The `top_p` (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.
          format: float
          example: 0.7
          default: 0.7
        top_k:
          type: number
          format: float
          example: 50
        frequency_penalty:
          type: number
          format: float
          example: 0.5
        n:
          type: integer
          description: Number of generations to return
          example: 1
        response_format:
          type: object
          description: 'An object specifying the format that the model must output.'
          properties:
            type:
              type: string
              description: 'The type of the response format.'
              example: text
        tools:
          type: array
          description: >
                    A list of tools the model may call. Currently, only functions are supported as a tool.
                    Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.
          items:
            $ref: "#/components/schemas/ChatCompletionTool"
        # tool_choice:
        #   $ref: "#/components/schemas/ChatCompletionToolChoiceOption"


    ChatCompletionVLMRequest:
      title: VLM
      type: object
      required:
        - model
        - messages
      properties:
        model:
          type: string
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.**For a complete list of available models, please check the [Models](https://cloud.siliconflow.cn/sft-d29cs9gh3vvc73c59kb0/models?tags=%E8%A7%86%E8%A7%89)**.

          example: deepseek-ai/DeepSeek-OCR
          default: deepseek-ai/DeepSeek-OCR
          enum:
            - deepseek-ai/DeepSeek-OCR
            - Qwen/Qwen3-VL-30B-A3B-Instruct
            - Qwen/Qwen3-Omni-30B-A3B-Instruct
            - zai-org/GLM-4.6V
            - Qwen/Qwen2.5-VL-72B-Instruct

     

        messages:
          type: array
          description: A list of messages comprising the conversation so far.
          items:
            type: object
            properties:
              role:
                type: string
                description: 'The role of the messages author. Choice between: system, user, or assistant.'
                example: user
                default: user
                enum:
                  - user
                  - assistant
                  - system
              content:
                oneOf:
                  - type: array
                    description: An array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images. You can pass multiple images by adding multiple `image_url` content parts. The Qwen3-Omni series supports `video_url` and `audio_url`, enabling the recognition of video and audio content. The Qwen3-VL model also supports `video_url`, allowing it to recognize video content. Recommend videos and audio within 30 seconds.
                    items:
                      $ref: "#/components/schemas/ChatCompletionRequestUserMessageContentPart"
                    minItems: 1
            required:
              - role
              - content
          minItems: 1
          maxItems: 10
        stream:
          type: boolean
          description: "If set, tokens are returned as Server-Sent Events as they are made available. Stream terminates with `data: [DONE]`"
          example: false
          default: false
        max_tokens:
          type: integer
          description: >
            The maximum number of tokens to generate. Ensure that input tokens + max_tokens do not exceed the model’s context window. As some services are still being updated, avoid setting max_tokens to the window’s upper bound; reserve ~10k tokens as buffer for input and system overhead. See Models(https://cloud.siliconflow.cn/models) for details. 
        stop:
          description: >
            Up to 4 sequences where the API will stop generating further tokens.
            The returned text will not contain the stop sequence.
          default: []
          nullable: true
          oneOf:
            - type: array
              minItems: 1
              maxItems: 4
              items:
                type: string
                example: "null"
            - type: string
              default: <|endoftext|>
              example: "\n"
              nullable: true
            - type: string
              default: <|endoftext|>
              example: ""
              nullable: true


        temperature:
          type: number
          description: Determines the degree of randomness in the response.
          format: float
          example: 0.7
          default: 0.7
        top_p:
          type: number
          description: The `top_p` (nucleus) parameter is used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities.
          format: float
          example: 0.7
          default: 0.7
        top_k:
          type: number
          format: float
          example: 50
          default: 50
        frequency_penalty:
          type: number
          format: float
          example: 0.5
          default: 0.5
        n:
          type: integer
          description: Number of generations to return
          example: 1
          default: 1
        response_format:
          type: object
          description: 'An object specifying the format that the model must output.'
          properties:
            type:
              type: string
              description: 'The type of the response format.'
              example: text


    ChatCompletionResponse:
      type: object
      properties:
        id:
          type: string
        choices:
          $ref: "#/components/schemas/ChatCompletionChoicesData"
        usage:
          $ref: "#/components/schemas/UsageData"
        created:
          type: integer
        model:
          type: string
        object:
          type: string
          enum:
            - chat.completion

    MessgesResponse:
      type: object
      properties:
        id:
          type: string
        type:
            default: message
            description: |-
              Object type.

              For Messages, this is always `"message"`.
            enum:
              - message
            title: Type
            type: string
        role:
              default: assistant
              description: |-
                Conversational role of the generated message.

                This will always be `"assistant"`.
              enum:
                - assistant
              title: Role
              type: string
        content:
              description: >-
                Content generated by the model.


                This is an array of content blocks, each of which has a
                `type` that determines its shape.


                Example:


                ```json

                [{"type": "text", "text": "Hi"}]

                ```


                If the request input `messages` ended with an `assistant`
                turn, then the response `content` will continue directly
                from that last turn. You can use this to constrain the
                model's output.


                For example, if the input `messages` were:

                ```json

                [
                  {"role": "user", "content": "What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun"},
                  {"role": "assistant", "content": "The best answer is ("}
                ]

                ```


                Then the response `content` might be:


                ```json

                [{"type": "text", "text": "B)"}]

                ```
              items:
                oneOf:
                  - $ref: >-
                      #/components/schemas/ResponseToolUseBlock
              title: Content
              type: array
        model:
            description: The model that handled the request.
            title: Model
            type: string
        stop_reason:
              anyOf:
                - enum:
                    - end_turn
                    - max_tokens
                    - tool_use
                    - refusal
                  type: string
              description: >-
                The reason that we stopped.


                This may be one the following values:

                * `"end_turn"`: the model reached a natural stopping point or one of your provided custom
                `stop_sequences` was generated

                * `"max_tokens"`: we exceeded the requested `max_tokens`
                or the model's maximum

                * `"tool_use"`: the model invoked one or more tools

                * `"refusal"`: when streaming classifiers intervene to
                handle potential policy violations


                In non-streaming mode this value is always non-null. In
                streaming mode, it is null in the `message_start` event
                and non-null otherwise.
              title: Stop Reason
        stop_sequence:
              anyOf:
                - type: string
              default: null
              description: >-
                Which custom stop sequence was generated, if any.


                This value will be a non-null string if one of your custom
                stop sequences was generated.
              title: Stop Sequence
        usage:
          allOf:
            - $ref: '#/components/schemas/Usage'
              description: >-
                Billing and rate-limit usage.
              examples:
                - input_tokens: 2095
                  output_tokens: 503

    Usage:
      properties:
        input_tokens:
          description: The number of input tokens which were used.
          minimum: 0
          title: Input Tokens
          type: integer
        output_tokens:
          description: The number of output tokens which were used.
          minimum: 0
          title: Output Tokens
          type: integer
      required:
        - input_tokens
        - output_tokens
      title: Usage
      type: object


    ResponseToolUseBlock:
      properties:
        id:
          title: Id
          type: string
        input:
          title: Input
          type: object
        name:
          minLength: 1
          title: Name
          type: string
        type:
          default: tool_use
          enum:
            - tool_use
          title: Type
          type: string
      required:
        - id
        - input
        - name
        - type
      title: Tool use
      type: object

    ChatCompletionMessageToolCalls:
      type: array
      description: The tool calls generated by the model, such as function calls.
      items:
          $ref: "#/components/schemas/ChatCompletionMessageToolCall"

    ChatCompletionMessageToolCall:
      type: object
      properties:
          # TODO: index included when streaming
          id:
              type: string
              description: The ID of the tool call.
          type:
              type: string
              enum: ["function"]
              description: The type of the tool. Currently, only `function` is supported.
          function:
              type: object
              description: The function that the model called.
              properties:
                  name:
                      type: string
                      description: The name of the function to call.
                  arguments:
                      type: string
                      description: The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.
              required:
                  - name
                  - arguments
      required:
          - id
          - type
          - function

    ChatCompletionStream:
      type: object
      properties:
        id:
          type: string
        choices:
          $ref: "#/components/schemas/ChatCompletionChoicesData"
        created:
          type: integer
        model:
          type: string
        object:
          type: string
          enum:
            - chat.completion.chunk

    MessageResponseStream:
      type: object
      properties:
        id:
          type: string
        choices:
          $ref: "#/components/schemas/ChatCompletionChoicesData"
        created:
          type: integer
        model:
          type: string
        object:
          type: string
          enum:
            - chat.completion.chunk

    ChatCompletionEvent:
      type: object
      required: [ data ]
      properties:
        data:
          $ref: "#/components/schemas/ChatCompletionChunk"

    ChatCompletionChunk:
      type: object
      required: [ id, object, created, token, choices ]
      properties:
        id:
          type: string
        object:
          type: string
          enum:
            - chat.completion.chunk
        created:
          type: integer
        token:
          $ref: "#/components/schemas/ChatCompletionToken"
        choices:
          title: ChatCompletionChoices
          type: array
          items:
            $ref: "#/components/schemas/ChatCompletionChoice"
        usage:
          allOf:
            - $ref: "#/components/schemas/UsageData"
            - nullable: true
        finish_reason:
          allOf:
            - $ref: "#/components/schemas/FinishReason"
            - nullable: true

    ChatCompletionToken:
      type: object
      required: [ id, text, logprob, special ]
      properties:
        id:
          type: integer
        text:
          type: string
        logprob:
          type: number
          format: float
        special:
          type: boolean

    ChatCompletionChoice:
      type: object
      required: [ index, delta ]
      properties:
        index:
          type: integer
        delta:
          title: ChatCompletionChoiceDelta
          type: object
          required: [ content ]
          properties:
            content:
              type: string

    MessagesTool:
      type: object
      properties:
        name:
          description: >-
              Name of the tool.


              This is how the tool will be called by the model and in `tool_use`
              blocks.
          title: Name
          type: string
        input_schema:
          $ref: '#/components/schemas/InputSchema'
          description: >-
            [JSON schema](https://json-schema.org/draft/2020-12) for this tool's
            input.

            This defines the shape of the `input` that your tool accepts and
            that the model will produce.
      required:
          - name
          - input_schema

    InputSchema:
      type: object
      properties:
          properties:
            anyOf:
              - type: object
            title: Properties
          required:
            anyOf:
              - items:
                  type: string
                type: array
            title: Required
          type:
            enum:
              - object
            title: Type
            type: string
      required:
        - type
      


    ChatCompletionTool:
        type: object
        properties:
            type:
                type: string
                enum: ["function"]
                description: The type of the tool. Currently, only `function` is supported.
            function:
                $ref: "#/components/schemas/FunctionObject"
        required:
            - type
            - function


    FunctionObject:
        type: object
        properties:
            description:
                type: string
                description: A description of what the function does, used by the model to choose when and how to call the function.
            name:
                type: string
                description: The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
            parameters:
                $ref: "#/components/schemas/FunctionParameters"
            strict:
              type: boolean
              nullable: true
              default: false
              description: Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](docs/guides/function-calling).
        required:
            - name

    FunctionParameters:
        type: object
        description: "The parameters the functions accepts, described as a JSON Schema object. See the [guide](/guides/function_calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format. \n\nOmitting `parameters` defines a function with an empty parameter list."
        additionalProperties: true

    ChatCompletionToolChoiceOption:
        description: |
            Controls which (if any) tool is called by the model.
            `none` means the model will not call any tool and instead generates a message.
            `auto` means the model can pick between generating a message or calling one or more tools.
            Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

            `none` is the default when no tools are present. `auto` is the default if tools are present.
        oneOf:
            - type: string
              description: >
                  `none` means the model will not call any tool and instead generates a message.
                  `auto` means the model can pick between generating a message or calling one or more tools.
              enum: [none, auto]
            - $ref: "#/components/schemas/ChatCompletionNamedToolChoice"

    ChatCompletionNamedToolChoice:
        type: object
        description: Specifies a tool the model should use. Use to force the model to call a specific function.
        properties:
            type:
                type: string
                enum: ["function"]
                description: The type of the tool. Currently, only `function` is supported.
            function:
                type: object
                properties:
                    name:
                        type: string
                        description: The name of the function to call.
                required:
                    - name
        required:
            - type
            - function

    upload_image:
      title: Upload Image
      description: The image that needs to be uploaded should be converted into base64 format like "data:image/png;base64, XXX"
      type: string
      example: data:image/png;base64, XXX

    upload_image_url:
      title: Upload Image
      description: The image used for uploading a raw video can be in base64 format or a URL.
      type: string
      enum:
        - data:image/png;base64, XXX
        - img_url
      example:  https://inews.gtimg.com/om_bt/Os3eJ8u3SgB3Kd-zrRRhgfR5hUvdwcVPKUTNO6O7sZfUwAA/641

    upload_image_url_array:
      title: Upload Image
      description: The image used for uploading a raw video can be in base64 format or a URL. This field is only applicable to Qwen/Qwen-Image-Edit-2509.
      type: string
      enum:
        - data:image/png;base64, XXX
        - img_url
      example:  https://inews.gtimg.com/om_bt/Os3eJ8u3SgB3Kd-zrRRhgfR5hUvdwcVPKUTNO6O7sZfUwAA/641


    stable-diffusion-3-5-large:
      title: stabilityai
      type: object
      required:
        - model
        - prompt
        - image_size
        - batch_size
        - num_inference_steps
        - guidance_scale
      properties:
        model:
          type: string
          default: stabilityai/stable-diffusion-3-5-large
          enum:
            - stabilityai/stable-diffusion-3-5-large
            - stabilityai/stable-diffusion-3-5-large-turbo
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
        prompt:
          type: string
          default: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea
        negative_prompt:
          title: Negative Prompt
          type: string
          description: Negative Prompt
        image_size:
          title: Image Size
          description: Image Size
          enum:
            - 1024x1024
            - 512x1024
            - 768x512
            - 768x1024
            - 1024x576
            - 576x1024
          default: 1024x1024
        batch_size:
          title: Number Images
          description: Number Images
          type: integer
          minimum: 1
          maximum: 4
          default: 1
        seed:
          title: Seed
          type: integer
          minimum: 0
          maximum: 9999999999
        num_inference_steps:
          title: Number Inference Steps
          description: Number inference steps，among them, 'stable-diffusion-3-5-large-turbo' is a fixed value of 4.
          type: integer
          minimum: 1
          maximum: 50
          default: 20
        guidance_scale:
          title: Guidance Scale
          description: This value is used to control the degree of match between the generated image and the given prompt. The higher the value, the more the generated image will tend to strictly match the text prompt. The lower the value, the more creative and diverse the generated image will be, potentially containing more unexpected elements.
          type: number
          minimum: 0
          maximum: 20
          default: 7.5
        prompt_enhancement: 
          type: boolean
          description: Prompt enhancement switch, When enabled, the prompt is optimized to be detailed and model-friendly.
          example: false
          default: false

    Janus-Pro-7B:
      title: deepseekai
      type: object
      required:
        - model
        - prompt
      properties:
        model:
          type: string
          default: deepseek-ai/Janus-Pro-7B
          enum:
            - deepseek-ai/Janus-Pro-7B
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.The model defaults to generating images with a resolution of 384*384.
        prompt:
          type: string
          default: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea
        seed:
          title: Seed
          type: integer
          minimum: 0
          maximum: 9999999999


    FLUX.1-schnell:
      title: FLUX.1-schnell
      type: object
      required:
        - model
        - prompt
        - image_size
      properties:
        model:
          type: string
          default: black-forest-labs/FLUX.1-schnell
          enum:
            - black-forest-labs/FLUX.1-schnell
            - Pro/black-forest-labs/FLUX.1-schnell 
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
        prompt:
          type: string
          default: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea
        image_size:
          title: Image Size
          description: image size, format is [width]x[height]
          enum:
            - 1024x1024
            - 512x1024
            - 768x512
            - 768x1024
            - 1024x576
            - 576x1024
          default: 1024x1024
        seed:
          title: Seed
          type: integer
          minimum: 0
          maximum: 9999999999
        prompt_enhancement: 
          type: boolean
          description: Prompt enhancement switch, When enabled, the prompt is optimized to be detailed and model-friendly.
          example: false
          default: false

    FLUX.1-dev:
      title: FLUX.1-dev
      type: object
      required:
        - model
        - prompt
        - image_size
        - num_inference_steps
      properties:
        model:
          type: string
          default: black-forest-labs/FLUX.1-dev
          enum:
            - black-forest-labs/FLUX.1-dev
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
        prompt:
          type: string
          default: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea
        image_size:
          title: Image size, format is  [width]x[height], with a maximum of 2359296 pixels.
          enum:
            - 1024x1024
            - 960x1280
            - 768x1024
            - 720x1440
            - 720x1280
            - others
          default: 1024x1024
        seed:
          title: Seed
          type: integer
          minimum: 0
          maximum: 9999999999
        num_inference_steps:
          title: Number Inference Steps
          description: inference steps
          type: integer
          minimum: 1
          maximum: 30
          default: 20
        prompt_enhancement: 
          type: boolean
          description: Prompt enhancement switch, When enabled, the prompt is optimized to be detailed and model-friendly.
          example: false
          default: false
    fine-tune-image:
      title: fine-tune-image
      type: object
      required:
        - model
        - loras
        - prompt
        - image_size
      properties:
        model:
          type: string
          default: LoRA/black-forest-labs/FLUX.1-dev
          enum:
            - LoRA/black-forest-labs/FLUX.1-dev
          description: Input here is the name of the base LoRA.
        loras: 
          type: array
          description: List of the model's LoRA configurations.
          items:
            type: object
            properties:
              model_id:
                type: string
                description:  One of the fine-tuned model names, format is {user_id}:{suffix}:{uuid}:{check_point}. 
              strength:
                type: number
                format: float
                description: Each strength corresponds to the strength of a specific model, in a one-to-one relationship with model_id.
                minimum: 0
                maximum: 5
        prompt:
          type: string
          default: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea
        image_size:
          description: Image size, format is [width]x[height], with a maximum of 2359296 pixels.
          enum:
            - 1024x1024
            - 960x1280
            - 768x1024
            - 720x1440
            - 720x1280
            - others
          default: 1024x1024
        seed:
          type: integer
          minimum: 0
          maximum: 9999999999
        num_inference_steps:
          description: Inference steps
          type: integer
          minimum: 1
          maximum: 30
          default: 20
        prompt_enhancement: 
          type: boolean
          description: Prompt enhancement switch, When enabled, the prompt is optimized to be detailed and model-friendly.
          example: false
          default: false
    
    FLUX.1-pro:
      title: FLUX.1-pro
      type: object
      required:
        - model
        - prompt
        - width
        - height
      properties:
        model:
          type: string
          default: black-forest-labs/FLUX.1-pro
          enum:
            - black-forest-labs/FLUX.1-pro
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
        prompt:
          type: string
          default: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea
        image_prompt:
          type: string
          description: Optional base64 encoded image to use as a prompt for generation.
        width:
          type: integer
          description: Width of the generated image in pixels. It must be a multiple of 32.
          minimum: 256
          maximum: 1440
          default: 1024
        height:
          type: integer
          description: Width of the generated image in pixels. It must be a multiple of 32.
          minimum: 256
          maximum: 1440
          default: 768
        prompt_upsampling:
          type: boolean
          default: false
          description: Whether to upsample the prompt. If enabled, the prompt will be automatically adjusted to encourage more creative generation.
        seed:
          type: integer
          minimum: 0
          maximum: 9999999999
        steps:
          description: inference steps.
          type: integer
          minimum: 1
          maximum: 50
        guidance:
          type: number
          description:  This value is used to control the degree of match between the generated image and the given prompt. The higher the value, the more the generated image will tend to strictly match the text prompt. The lower the value, the more creative and diverse the generated image will be, potentially containing more unexpected elements.
          minimum: 1.5
          maximum: 5
        safety_tolerance:
          type: integer
          description: Tolerance level for input and output review. Ranges from 0 to 6, where 0 is the strictest and 6 is the most lenient.
          minimum: 0
          maximum: 6
          default: 2
        interval:
          type: number
          description: Sampling parameter for guidance control.
          minimum: 1
          maximum: 4  
        output_format:
          type: string
          description: Output format for the generated image. It can be either 'jpeg' or 'png'.
          enum:
            - jpeg
            - png

    Kolors:
      title: Kolors
      type: object
      required:
        - model
        - prompt
      properties:
        model:
          type: string
          enum:
            - Qwen/Qwen-Image-Edit-2509
            - Qwen/Qwen-Image-Edit
            - Qwen/Qwen-Image
            - Kwai-Kolors/Kolors
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible. **For a complete list of available models, please check the [Models](https://cloud.siliconflow.cn/sft-d29cs9gh3vvc73c59kb0/models?types=to-image)**.
        prompt:
          type: string
          example: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea
        negative_prompt:
          title: Negative Prompt
          type: string
          description: negative prompt
        image_size:
          type: string
          title:  Image size, format is  [width]x[height].
          description: >
            Image resolution in "widthxheight" format (Required). To ensure optimal quality, using the recommended values for your model is strongly advised. **Qwen/Qwen-Image-Edit-2509 and Qwen/Qwen-Image-Edit not support this field.**
              Recommended Values:  
              - For Kolor model:  
                - "1024x1024" (1:1)
                - "960x1280" (3:4)
                - "768x1024" (3:4)
                - "720x1440" (1:2)
                - "720x1280" (9:16)
              - For Qwen-Image model:  
                - "1328x1328" (1:1)
                - "1664x928" (16:9)
                - "928x1664" (9:16)
                - "1472x1140" (4:3)
                - "1140x1472" (3:4)
                - "1584x1056" (3:2)
                - "1056x1584" (2:3)
        batch_size:
          title: Number Images
          description: number of output images. Only applicable to Kwai-Kolors/Kolors.
          type: integer
          minimum: 1
          maximum: 4
          default: 1
        seed:
          title: Seed
          type: integer
          minimum: 0
          maximum: 9999999999
        num_inference_steps:
          title: Number Inference Steps
          description: number of inference steps
          type: integer
          minimum: 1
          maximum: 100
          default: 20
        guidance_scale:
          title: Guidance Scale
          description: This value is used to control the degree of match between the generated image and the given prompt. The higher the value, the more the generated image will tend to strictly match the text prompt. The lower the value, the more creative and diverse the generated image will be, potentially containing more unexpected elements. Only applicable to Kwai-Kolors/Kolors.
          type: number
          minimum: 0
          maximum: 20
          default: 7.5
        cfg:
          title: CFG Scale
          type: number
          description: CFG (Classifier-Free Guidance) is a technique that adjusts how closely generated outputs follow input prompts by balancing precision and creativity. This field is only applicable to Qwen/Qwen-Image models. For text generation scenarios, the CFG value must be greater than 1. The official configuration uses 50 steps with CFG 4.0. When CFG is set too small, it becomes nearly impossible to generate text.
          minimum: 0.1
          maximum: 20
        image:
          $ref: "#/components/schemas/upload_image_url"
        image2:
          $ref: "#/components/schemas/upload_image_url_array"
        image3:
          $ref: "#/components/schemas/upload_image_url_array"

    stable-diffusion-2-1:
      title: stable-diffusion-2-1
      type: object
      required:
        - model
        - prompt
        - image_size
        - batch_size
        - num_inference_steps
        - guidance_scale
      properties:
        model:
          type: string
          default: stabilityai/stable-diffusion-2-1
          enum:
            - stabilityai/stable-diffusion-2-1
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
        prompt:
          type: string
          default: an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea
        negative_prompt:
          title: Negative Prompt
          type: string
        image_size:
          title: Image Size
          enum:
            - 512x512
            - 512x1024
            - 768x512
            - 768x1024
            - 1024x576
            - 576x1024
          default: 512x512
        batch_size:
          title: Number Images
          type: integer
          minimum: 1
          maximum: 4
          default: 1
        seed:
          title: Seed
          type: integer
          minimum: 0
          maximum: 9999999999
        num_inference_steps:
          title: Number Inference Steps
          type: integer
          minimum: 1
          maximum: 100
          default: 20
        guidance_scale:
          title: Guidance Scale
          type: number
          minimum: 0
          maximum: 20
          default: 7.5
        image:
          $ref: "#/components/schemas/upload_image"


    ImagesGenerationResponse:
      type: object
      properties:
        images:
          type: array
          items:
            type: object
            properties:
              url:
                description:  The URL for the generated image is valid for one hour. Please make sure to download and store it promptly to avoid any issues due to URL expiration.
                type: string
        timings:
          type: object
          properties:
            inference:
              type: number
              format: float
        seed:
          type: integer

    fish-speech-1.4:
      title: fish-speech-1.4
      type: object
      required:
        - model
        - input
        - voice
      additionalProperties: false
      properties:
        model:
            type: string
            enum:
              - fishaudio/fish-speech-1.4
            description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
        input:
            type: string
            description: The text to generate audio for.
            maxLength: 128000
            minLength: 1
        voice:
            type: string
            enum: [
                  "fishaudio/fish-speech-1.4:alex",
                  "fishaudio/fish-speech-1.4:anna",
                  "fishaudio/fish-speech-1.4:bella",
                  "fishaudio/fish-speech-1.4:benjamin",
                  "fishaudio/fish-speech-1.4:charles",
                  "fishaudio/fish-speech-1.4:claire",
                  "fishaudio/fish-speech-1.4:david",
                  "fishaudio/fish-speech-1.4:diana"
            ]
        response_format:
            description: "The format to audio out. Supported formats are `mp3`, `opus`, `wav`, `pcm`"
            default: "mp3"
            type: string
            enum: ["mp3", "opus", "wav", "pcm"]
        sample_rate:
            description: "Control the output sample rate. The default values and differ for different video output types, as follows: opus: Supports 48000 Hz. wav, pcm: Supports 8000, 16000, 24000, 32000, 44100 Hz, with a default of 44100 Hz. mp3: Supports 32000, 44100 Hz, with a default of 44100 Hz."
            type: number
            enum: [8000, 16000, 24000, 32000, 44100, 48000]
        stream:
            description: "streaming or not"
            type: boolean
            default: true
        speed:
            type: number
            description: The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.
            format: float
            minimum: 0.25
            maximum: 4.0
            default: 1.0
        gain:
            type: number
            format: float
            minimum: -10.0
            maximum: 10.0
            default: 0.00
    fish-speech-1.5:
      title: fish-speech-1.5 
      type: object
      required:
        - model
        - input
        - voice
      additionalProperties: false
      properties:
        model:
            type: string
            enum:
              - fishaudio/fish-speech-1.5
            description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
        input:
            type: string
            description: The text to generate audio for.
            example: The text to generate audio for
            maxLength: 128000
            minLength: 1
        voice:
            type: string
            enum: [
                  "fishaudio/fish-speech-1.5:alex",
                  "fishaudio/fish-speech-1.5:anna",
                  "fishaudio/fish-speech-1.5:bella",
                  "fishaudio/fish-speech-1.5:benjamin",
                  "fishaudio/fish-speech-1.5:charles",
                  "fishaudio/fish-speech-1.5:claire",
                  "fishaudio/fish-speech-1.5:david",
                  "fishaudio/fish-speech-1.5:diana"
            ]
        response_format:
            description: "The format to audio out. Supported formats are `mp3`, `opus`, `wav`, `pcm`"
            default: "mp3"
            type: string
            enum: ["mp3", "opus", "wav", "pcm"]
        sample_rate:
            description: "Control the output sample rate. The default values and differ for different video output types, as follows: opus: Supports 48000 Hz. wav, pcm: Supports 8000, 16000, 24000, 32000, 44100 Hz, with a default of 44100 Hz. mp3: Supports 32000, 44100 Hz, with a default of 44100 Hz."
            type: number
            example: 32000
            enum: [8000, 16000, 24000, 32000, 44100, 48000]
        stream:
            description: "streaming or not"
            type: boolean
            default: true
        speed:
            type: number
            description: The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.
            format: float
            minimum: 0.25
            maximum: 4.0
            default: 1.0
        gain:
            type: number
            format: float
            minimum: -10.0
            maximum: 10.0
            default: 0.00
    GPT-SoVITS:
      title: GPT-SoVITS
      type: object
      required:
        - model
        - input
        - voice
      additionalProperties: false
      properties:
        model:
            type: string
            enum:
              - RVC-Boss/GPT-SoVITS
            description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
        input:
            type: string
            description: The text to generate audio for.
            maxLength: 128000
            minLength: 1
        voice:
            type: string
            enum: [
                  "RVC-Boss/GPT-SoVITS:alex",
                  "RVC-Boss/GPT-SoVITS:anna",
                  "RVC-Boss/GPT-SoVITS:bella",
                  "RVC-Boss/GPT-SoVITS:benjamin",
                  "RVC-Boss/GPT-SoVITS:charles",
                  "RVC-Boss/GPT-SoVITS:claire",
                  "RVC-Boss/GPT-SoVITS:david",
                  "RVC-Boss/GPT-SoVITS:diana"
            ]
        response_format:
            description: "The format to audio out. Supported formats are `mp3`, `opus`, `wav`, `pcm`"
            default: "mp3"
            type: string
            enum: ["mp3", "opus", "wav", "pcm"]
        sample_rate:
            description: "Control the output sample rate. The default values and differ for different video output types, as follows: opus: Supports 48000 Hz. wav, pcm: Supports 8000, 16000, 24000, 32000, 44100 Hz, with a default of 44100 Hz. mp3: Supports 32000, 44100 Hz, with a default of 44100 Hz."
            type: number
            enum: [8000, 16000, 24000, 32000, 44100, 48000]
        stream:
            description: "streaming or not"
            type: boolean
            default: true
        speed:
            type: number
            description: The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.
            format: float
            minimum: 0.25
            maximum: 4.0
            default: 1.0
        gain:
            type: number
            format: float
            minimum: -10.0
            maximum: 10.0
            default: 0.00
            
    CosyVoice2-0.5B:
      title: CosyVoice2-0.5B
      type: object
      required:
        - model
        - input
      additionalProperties: false
      properties:
        model:
            type: string
            enum:
              - FunAudioLLM/CosyVoice2-0.5B
            description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
        input:
            type: string
            description: For natural language instructions, add a special end marker "<|endofprompt|>" before the natural language description. These descriptions cover aspects such as emotion, speaking speed, role-playing, and dialects. For detailed instructions, insert pitch bursts between text markers, using markers like "[laughter]" and "[breath]." Additionally, we apply pitch feature markers to phrases; for example:Can you say it with a happy emotion? <|endofprompt|> Today is really happy, Spring Festival is coming! I’m so happy, Spring Festival is coming! [laughter] [breath].
            example: Can you say it with a happy emotion? <|endofprompt|>I'm so happy, Spring Festival is coming! 
            default: Can you say it with a happy emotion? <|endofprompt|>I'm so happy, Spring Festival is coming! 
          
            maxLength: 128000
            minLength: 1
        voice:
            type: string
            enum: [
                  "FunAudioLLM/CosyVoice2-0.5B:alex",
                  "FunAudioLLM/CosyVoice2-0.5B:anna",
                  "FunAudioLLM/CosyVoice2-0.5B:bella",
                  "FunAudioLLM/CosyVoice2-0.5B:benjamin",
                  "FunAudioLLM/CosyVoice2-0.5B:charles",
                  "FunAudioLLM/CosyVoice2-0.5B:claire",
                  "FunAudioLLM/CosyVoice2-0.5B:david",
                  "FunAudioLLM/CosyVoice2-0.5B:diana"
            ]
        references:
            description: The voice field and references field are mutually exclusive. 
            type: array
            items:
              type: object
              properties:
                audio:
                  oneOf:
                    - type: string
                      format: uri
                      description: A URL pointing to an audio file (e.g., `https://example.com/audio.mp3`).
                    - type: string
                      pattern: ^data:audio\/\w+;base64,[A-Za-z0-9+/=]+$
                      description: A base64-encoded audio string (e.g., `data:audio/mp3;base64,ABC123...`).
                text:
                  description: The audio content, which can be either a URL pointing to an audio file or a base64-encoded audio string.
                  type: string
        response_format:
            description: "The format to audio out. Supported formats are `mp3`, `opus`, `wav`, `pcm`"
            default: "mp3"
            type: string
            enum: ["mp3", "opus", "wav", "pcm"]
        sample_rate:
            description: "Control the output sample rate. The default values and differ for different video output types, as follows: opus: Supports 48000 Hz. wav, pcm: Supports 8000, 16000, 24000, 32000, 44100 Hz, with a default of 44100 Hz. mp3: Supports 32000, 44100 Hz, with a default of 44100 Hz."
            type: number
            default: 32000
        stream:
            description: "streaming or not"
            type: boolean
        speed:
            type: number
            description: The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.
            format: float
            minimum: 0.25
            maximum: 4.0
            default: 1.0
        gain:
            type: number
            format: float
            minimum: -10.0
            maximum: 10.0
            default: 0.00


    IndexTTS-2:
      title: IndexTTS-2
      type: object
      required:
        - model
        - input
      additionalProperties: false
      properties:
        model:
            type: string
            enum:
              - IndexTeam/IndexTTS-2
            description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
        input:
            type: string
            description: For natural language instructions, add a special end marker "<|endofprompt|>" before the natural language description. These descriptions cover aspects such as emotion, speaking speed, role-playing, and dialects. For detailed instructions, insert pitch bursts between text markers, using markers like "[laughter]" and "[breath]." Additionally, we apply pitch feature markers to phrases; for example:Can you say it with a happy emotion? <|endofprompt|> Today is really happy, Spring Festival is coming! I’m so happy, Spring Festival is coming! [laughter] [breath].
            example: Can you say it with a happy emotion? <|endofprompt|>I'm so happy, Spring Festival is coming! 
            default: Can you say it with a happy emotion? <|endofprompt|>I'm so happy, Spring Festival is coming! 
            maxLength: 128000
            minLength: 1
        voice:
            type: string
            enum: [
                  "IndexTeam/IndexTTS-2:alex",
                  "IndexTeam/IndexTTS-2:anna",
                  "IndexTeam/IndexTTS-2:bella",
                  "IndexTeam/IndexTTS-2:benjamin",
                  "IndexTeam/IndexTTS-2:charles",
                  "IndexTeam/IndexTTS-2:claire",
                  "IndexTeam/IndexTTS-2:david",
                  "IndexTeam/IndexTTS-2:diana"
            ]
        references:
            description: The voice field and references field are mutually exclusive. 
            type: array
            items:
              type: object
              properties:
                audio:
                  oneOf:
                    - type: string
                      format: uri
                      description: A URL pointing to an audio file (e.g., `https://example.com/audio.mp3`).
                    - type: string
                      pattern: ^data:audio\/\w+;base64,[A-Za-z0-9+/=]+$
                      description: A base64-encoded audio string (e.g., `data:audio/mp3;base64,ABC123...`).
                text:
                  description: The audio content, which can be either a URL pointing to an audio file or a base64-encoded audio string.
                  type: string


    MOSS-TTSD-v0.5:
      title: MOSS-TTSD-v0.5
      type: object
      required:
        - model
        - input
      additionalProperties: false
      properties:
        model:
            type: string
            enum:
              - fnlp/MOSS-TTSD-v0.5
            description: >
              MOSS-TTSD (text to spoken dialogue) is an open-source bilingual spoken dialogue synthesis model that supports both Chinese and English. It can transform dialogue scripts between two speakers into natural, expressive conversational speech. MOSS-TTSD supports voice cloning and long single-session speech generation, making it ideal for AI podcast production.
              

              To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
        input:
            type: string
            description: >
              The dialogue text uses speaker tags to indicate turns:

              [S1]: Indicates Speaker 1 is speaking
              
              [S2]: Indicates Speaker 2 is speaking
            example: "[S1]Hello, how are you today?[S2]I'm doing great, thanks for asking![S1]That's wonderful to hear "
            maxLength: 128000
            minLength: 1
        max_tokens:
          type: integer
          description: The maximum number of tokens to generate. The input + output does not exceed 32k tokens.
          default: 2048
          example: 4096
        references:
            description: The voice field and references field are mutually exclusive. If you want to use scripted dialogue, you need to pass two voice tones through the references field. Scripted dialogue is only available for the moss model.
            type: array
            items:
              type: object
              properties:
                audio:
                  oneOf:
                    - type: string
                      format: url
                      description: A URL pointing to an audio file (e.g., `https://example.com/audio.mp3`).
                    - type: string
                      pattern: ^data:audio\/\w+;base64,[A-Za-z0-9+/=]+$
                      description: A base64-encoded audio string (e.g., `data:audio/mp3;base64,ABC123...`).
                text:
                  description: The audio content, which can be either a URL pointing to an audio file or a base64-encoded audio string.
                  type: string
        voice:
            description:  The "voice" field currently does not support two timbres. If you need to upload two timbres, please use "reference".
            type: string
            enum: [
                  "fnlp/MOSS-TTSD-v0.5:alex",
                  "fnlp/MOSS-TTSD-v0.5:anna",
                  "fnlp/MOSS-TTSD-v0.5:bella",
                  "fnlp/MOSS-TTSD-v0.5:benjamin",
                  "fnlp/MOSS-TTSD-v0.5:charles",
                  "fnlp/MOSS-TTSD-v0.5:claire",
                  "fnlp/MOSS-TTSD-v0.5:david",
                  "fnlp/MOSS-TTSD-v0.5:diana"
            ]
        response_format:
            description: "The format to audio out. Supported formats are `mp3`, `opus`, `wav`, `pcm`"
            default: "mp3"
            type: string
            enum: ["mp3", "opus", "wav", "pcm"]
        sample_rate:
            description: "Control the output sample rate. The default values and differ for different video output types, as follows: opus: Supports 48000 Hz. wav, pcm: Supports 8000, 16000, 24000, 32000, 44100 Hz, with a default of 44100 Hz. mp3: Supports 32000, 44100 Hz, with a default of 44100 Hz."
            type: number
            default: 32000
        stream:
            description: "streaming or not"
            type: boolean
            default: true
        speed:
            type: number
            description: The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default.
            format: float
            minimum: 0.25
            maximum: 4.0
            default: 1.0
        gain:
            type: number
            format: float
            minimum: -10.0
            maximum: 10.0
            default: 0.00


    Lightricks_LTX-Video:
      title: Lightricks/LTX-Video
      type: object
      required:
        - model
        - prompt
      properties:
        model:
          type: string
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
          enum:
            - Lightricks/LTX-Video
        prompt:
          type: string
          description: The text prompt to generate the video description from.
        image: 
          type: string
          description: The input only supports image links via URL.
        seed:
          type: integer
          description: The seed for the random number generator.

    tencent_HunyuanVideo:
      title: HunyuanVideo
      type: object
      required:
        - model
        - prompt
      properties:
        model:
          type: string
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
          enum:
            - tencent/HunyuanVideo
        prompt:
          type: string
          description: The text prompt to generate the video description from.
        seed:
          type: integer
          description: The seed for the random number generator.

    T2V:
      title: Wan-AI 文生视频
      type: object
      required:
        - model
        - prompt
        - image_size
      properties:
        model:
          type: string
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible.
          enum:
            - Wan-AI/Wan2.1-T2V-14B
            - Wan-AI/Wan2.1-T2V-14B-Turbo
        prompt:
          type: string
          description: The text prompt to generate the video description from.
        negative_prompt:
          type: string
          description: negative prompt
        image_size:
          type: string
          description: Length-width ratio of the generated image.
          enum: ["1280x720","720x1280","960x960"]
        seed:
          type: integer
          description: The seed for the random number generator. 


    I2V:
      title: Wan-AI 
      type: object
      required:
        - model
        - prompt
        - image_size
      properties:
        model:
          type: string
          example: Wan-AI/Wan2.2-I2V-A14B
          description: Corresponding Model Name. To better enhance service quality, we will make periodic changes to the models provided by this service, including but not limited to model on/offlining and adjustments to model service capabilities. We will notify you of such changes through appropriate means such as announcements or message pushes where feasible. **For a complete list of available models, please check the [Models](https://cloud.siliconflow.cn/sft-d29cs9gh3vvc73c59kb0/models?types=to-video)**.
          enum:
            - Wan-AI/Wan2.2-I2V-A14B
            - Wan-AI/Wan2.2-T2V-A14B
        prompt:
          type: string
          description: The text prompt to generate the video description from.
        negative_prompt:
          type: string
          description: negative prompt
        image_size:
          type: string
          description: Length-width ratio of the generated image.
          enum: ["1280x720","720x1280","960x960"]
        image:
          description: When selecting the model Wan-AI/Wan2.2-I2V-14B-720P, the image parameter is a required field.
          $ref: "#/components/schemas/upload_image_url"
        seed:
          type: integer
          description: The seed for the random number generator. 


    getVideosRequest:
      type: object
      required:
        - requestId
      properties:
        requestId:
          type: string
          description: The requestId returned by the interface submit.
  

    getVideosResponse:
      type: object
      properties:
        status:
          type: string
          description: Status of the operation. Possible values are 'Succeed','InQueue','InProgress','Failed'.
          enum:
            - Succeed
            - InQueue
            - InProgress
            - Failed
        reason:
          type: string
          description: Reason for the operation
        results:
          type: object
          properties:
            videos:
              type: array
              items:
                type: object
                properties:
                  url:
                    type: string
                    description: The URL for the generated video is valid for one hour. Please make sure to download and store it promptly to avoid any issues due to URL expiration.
            timings:
              type: object
              properties:
                inference:
                  type: number
                  format: double
                  description: Inference time
            seed:
              type: integer
              description: Seed value
